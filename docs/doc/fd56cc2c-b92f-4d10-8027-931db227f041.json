{
    "summary": "This DDPM module in PyTorch Lightning defines a model for predicting start values and generating images using LatentDiffusion class, includes conditional stages, and computes mean and variance.",
    "details": [
        {
            "comment": "This code appears to be a mixture of various sources and serves as a module for denoising diffusion probability models. It includes functions for making beta schedules, creating diagonal Gaussian distributions, and handling different conditioning keys. The code also utilizes the PyTorch Lightning framework for training and includes various other import statements from related modules. The main logger is being used to log important information during execution.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":0-31",
            "content": "\"\"\"\nwild mixture of\nhttps://github.com/openai/improved-diffusion/blob/e94489283bb876ac1477d5dd7709bbbd2d9902ce/improved_diffusion/gaussian_diffusion.py\nhttps://github.com/lucidrains/denoising-diffusion-pytorch/blob/7706bdfc6f527f58d33f84b7b522e61e6e3164b3/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py\nhttps://github.com/CompVis/taming-transformers\n-- merci\n\"\"\"\nfrom functools import partial\nfrom contextlib import contextmanager\nimport numpy as np\nfrom tqdm import tqdm\nfrom einops import rearrange, repeat\nimport logging\nmainlogger = logging.getLogger('mainlogger')\nimport torch\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nimport pytorch_lightning as pl\nfrom utils.utils import instantiate_from_config\nfrom lvdm.ema import LitEma\nfrom lvdm.distributions import DiagonalGaussianDistribution\nfrom lvdm.models.utils_diffusion import make_beta_schedule\nfrom lvdm.basics import disabled_train\nfrom lvdm.common import (\n    extract_into_tensor,\n    noise_like,\n    exists,\n    default\n)\n__conditioning_keys__ = {'concat': 'c_concat',"
        },
        {
            "comment": "This code defines a class for DDPM (Denoising Diffusion Probabilistic Models) with Gaussian diffusion in image space. It includes various parameters such as unet_config, timesteps, beta_schedule, loss_type, ckpt_path, ignore_keys, load_only_unet, monitor, use_ema, first_stage_key, image_size, channels, log_every_t, clip_denoised, linear_start, linear_end, cosine_s, given_betas, original_elbo_weight, v_posterior, l_simple_weight, and conditioning_key.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":32-59",
            "content": "                         'crossattn': 'c_crossattn',\n                         'adm': 'y'}\nclass DDPM(pl.LightningModule):\n    # classic DDPM with Gaussian diffusion, in image space\n    def __init__(self,\n                 unet_config,\n                 timesteps=1000,\n                 beta_schedule=\"linear\",\n                 loss_type=\"l2\",\n                 ckpt_path=None,\n                 ignore_keys=[],\n                 load_only_unet=False,\n                 monitor=None,\n                 use_ema=True,\n                 first_stage_key=\"image\",\n                 image_size=256,\n                 channels=3,\n                 log_every_t=100,\n                 clip_denoised=True,\n                 linear_start=1e-4,\n                 linear_end=2e-2,\n                 cosine_s=8e-3,\n                 given_betas=None,\n                 original_elbo_weight=0.,\n                 v_posterior=0.,  # weight for choosing posterior variance as sigma = (1-v) * beta_tilde + v * beta\n                 l_simple_weight=1.,\n                 conditioning_key=None,"
        },
        {
            "comment": "This code initializes a class instance for a model that performs denoising diffusion probabilistic models (DDPMs). It takes several parameters including the model parameterization, whether to use positional encodings or not, and if logvar should be learned. The code checks the validity of the parameterization and logs the mode being used before setting up other attributes like clip_denoised, log_every_t, first_stage_key, channels, temporal_length, image_size, and use_positional_encodings.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":60-79",
            "content": "                 parameterization=\"eps\",  # all assuming fixed variance schedules\n                 scheduler_config=None,\n                 use_positional_encodings=False,\n                 learn_logvar=False,\n                 logvar_init=0.,\n                 ):\n        super().__init__()\n        assert parameterization in [\"eps\", \"x0\", \"v\"], 'currently only supporting \"eps\" and \"x0\" and \"v\"'\n        self.parameterization = parameterization\n        mainlogger.info(f\"{self.__class__.__name__}: Running in {self.parameterization}-prediction mode\")\n        self.cond_stage_model = None\n        self.clip_denoised = clip_denoised\n        self.log_every_t = log_every_t\n        self.first_stage_key = first_stage_key\n        self.channels = channels\n        self.temporal_length = unet_config.params.temporal_length\n        self.image_size = image_size  # try conv?\n        if isinstance(self.image_size, int):\n            self.image_size = [self.image_size, self.image_size]\n        self.use_positional_encodings = use_positional_encodings"
        },
        {
            "comment": "The code initializes a DDPM3d model with DiffusionWrapper, optionally an EMA copy of the model, and handles scheduler and checkpoint initialization. It also registers a schedule for betas, timesteps, and loss type.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":80-103",
            "content": "        self.model = DiffusionWrapper(unet_config, conditioning_key)\n        #count_params(self.model, verbose=True)\n        self.use_ema = use_ema\n        if self.use_ema:\n            self.model_ema = LitEma(self.model)\n            mainlogger.info(f\"Keeping EMAs of {len(list(self.model_ema.buffers()))}.\")\n        self.use_scheduler = scheduler_config is not None\n        if self.use_scheduler:\n            self.scheduler_config = scheduler_config\n        self.v_posterior = v_posterior\n        self.original_elbo_weight = original_elbo_weight\n        self.l_simple_weight = l_simple_weight\n        if monitor is not None:\n            self.monitor = monitor\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys=ignore_keys, only_model=load_only_unet)\n        self.register_schedule(given_betas=given_betas, beta_schedule=beta_schedule, timesteps=timesteps,\n                               linear_start=linear_start, linear_end=linear_end, cosine_s=cosine_s)\n        self.loss_type = loss_type"
        },
        {
            "comment": "The code initializes a DDPM model and registers a schedule for the given or computed betas using linear or cosine scheduling. The model's logvar is set based on the learn_logvar parameter, and the timesteps, linear_start, linear_end, and cosine_s values are registered to be used in the model.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":105-125",
            "content": "        self.learn_logvar = learn_logvar\n        self.logvar = torch.full(fill_value=logvar_init, size=(self.num_timesteps,))\n        if self.learn_logvar:\n            self.logvar = nn.Parameter(self.logvar, requires_grad=True)\n    def register_schedule(self, given_betas=None, beta_schedule=\"linear\", timesteps=1000,\n                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n        if exists(given_betas):\n            betas = given_betas\n        else:\n            betas = make_beta_schedule(beta_schedule, timesteps, linear_start=linear_start, linear_end=linear_end,\n                                       cosine_s=cosine_s)\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.linear_start = linear_start\n        self.linear_end = linear_end\n        assert alphas_cumprod.shape[0] == self.num_timesteps, 'alphas have to be defined for each timestep'"
        },
        {
            "comment": "This code initializes buffer attributes and performs calculations for diffusion models, including the variance of the posterior q(x_{t-1} | x_t, x_0). The operations include sqrt, log, and reciprocal functions. These steps are used to create a Diffusion model for data analysis.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":127-142",
            "content": "        to_torch = partial(torch.tensor, dtype=torch.float32)\n        self.register_buffer('betas', to_torch(betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = (1 - self.v_posterior) * betas * (1. - alphas_cumprod_prev) / (\n                    1. - alphas_cumprod) + self.v_posterior * betas"
        },
        {
            "comment": "This code defines and registers buffers for posterior variance, log of clipped posterior variance, and two mean coefficients. It then assigns weights based on the parameterization setting (either \"eps\" or \"x0\"). This appears to be part of a larger model used in a diffusion process.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":143-156",
            "content": "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n        self.register_buffer('posterior_variance', to_torch(posterior_variance))\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n        self.register_buffer('posterior_log_variance_clipped', to_torch(np.log(np.maximum(posterior_variance, 1e-20))))\n        self.register_buffer('posterior_mean_coef1', to_torch(\n            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n        self.register_buffer('posterior_mean_coef2', to_torch(\n            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n        if self.parameterization == \"eps\":\n            lvlb_weights = self.betas ** 2 / (\n                        2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod))\n        elif self.parameterization == \"x0\":\n            lvlb_weights = 0.5 * np.sqrt(torch.Tensor(alphas_cumprod)) / (2. * 1 - torch.Tensor(alphas_cumprod))"
        },
        {
            "comment": "This code defines a function that applies exponential moving average (EMA) to model parameters. If the parameterization is \"v\", it calculates lvlb_weights based on betas and alphas. It then registers the buffer 'lvlb_weights' for later use. The function also provides a context manager, ema_scope(), to switch between training weights (EMA) and current model weights.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":157-180",
            "content": "        elif self.parameterization == \"v\":\n            lvlb_weights = torch.ones_like(self.betas ** 2 / (\n                    2 * self.posterior_variance * to_torch(alphas) * (1 - self.alphas_cumprod)))\n        else:\n            raise NotImplementedError(\"mu not supported\")\n        # TODO how to choose this term\n        lvlb_weights[0] = lvlb_weights[1]\n        self.register_buffer('lvlb_weights', lvlb_weights, persistent=False)\n        assert not torch.isnan(self.lvlb_weights).all()\n    @contextmanager\n    def ema_scope(self, context=None):\n        if self.use_ema:\n            self.model_ema.store(self.model.parameters())\n            self.model_ema.copy_to(self.model)\n            if context is not None:\n                mainlogger.info(f\"{context}: Switched to EMA weights\")\n        try:\n            yield None\n        finally:\n            if self.use_ema:\n                self.model_ema.restore(self.model.parameters())\n                if context is not None:\n                    mainlogger.info(f\"{context}: Restored training weights\")"
        },
        {
            "comment": "The function `init_from_ckpt` loads a model from a checkpoint file path, deleting keys that start with specific ignore keys. It also returns the number of missing and unexpected keys. The `q_mean_variance` function computes the distribution q(x_t | x_0) for a given input tensor.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":182-203",
            "content": "    def init_from_ckpt(self, path, ignore_keys=list(), only_model=False):\n        sd = torch.load(path, map_location=\"cpu\")\n        if \"state_dict\" in list(sd.keys()):\n            sd = sd[\"state_dict\"]\n        keys = list(sd.keys())\n        for k in keys:\n            for ik in ignore_keys:\n                if k.startswith(ik):\n                    mainlogger.info(\"Deleting key {} from state_dict.\".format(k))\n                    del sd[k]\n        missing, unexpected = self.load_state_dict(sd, strict=False) if not only_model else self.model.load_state_dict(\n            sd, strict=False)\n        mainlogger.info(f\"Restored from {path} with {len(missing)} missing and {len(unexpected)} unexpected keys\")\n        if len(missing) > 0:\n            mainlogger.info(f\"Missing Keys: {missing}\")\n        if len(unexpected) > 0:\n            mainlogger.info(f\"Unexpected Keys: {unexpected}\")\n    def q_mean_variance(self, x_start, t):\n        \"\"\"\n        Get the distribution q(x_t | x_0).\n        :param x_start: the [N x C x ...] tensor of noiseless inputs."
        },
        {
            "comment": "The code defines a class with three methods: \"predict_start_from_noise\", \"predict_start_from_z_and_v\", and \"predict_start\". These methods are used for predicting the start values (x_start) of a diffusion process given different inputs such as noise, v, or z. The \"predict_start\" method takes t parameter which represents the number of diffusion steps. It returns mean, variance, and log_variance of x_start's shape. The \"predict_start_from_noise\" method uses sqrt_recip_alphas_cumprod and sqrt_recipm1_alphas_cumprod to predict the start value from noise. The \"predict_start_from_z_and_v\" method is used for predicting the start values from z and v.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":204-221",
            "content": "        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n        :return: A tuple (mean, variance, log_variance), all of x_start's shape.\n        \"\"\"\n        mean = (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start)\n        variance = extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape)\n        log_variance = extract_into_tensor(self.log_one_minus_alphas_cumprod, t, x_start.shape)\n        return mean, variance, log_variance\n    def predict_start_from_noise(self, x_t, t, noise):\n        return (\n                extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n                extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n        )\n    def predict_start_from_z_and_v(self, x_t, t, v):\n        # self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n        # self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n        return ("
        },
        {
            "comment": "This code defines several methods within a class. The `predict_eps_from_z_and_v` method predicts the epsilon from given z and v. The `q_posterior` method calculates the posterior mean, variance, and log variance clipped for a given x_start, x_t, and t. Finally, the `p_mean_variance` method calculates the mean and variance for a given x, t, and clip_denoised boolean.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":222-241",
            "content": "                extract_into_tensor(self.sqrt_alphas_cumprod, t, x_t.shape) * x_t -\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_t.shape) * v\n        )\n    def predict_eps_from_z_and_v(self, x_t, t, v):\n        return (\n                extract_into_tensor(self.sqrt_alphas_cumprod, t, x_t.shape) * v +\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_t.shape) * x_t\n        )\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = (\n                extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n                extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape) * x_t\n        )\n        posterior_variance = extract_into_tensor(self.posterior_variance, t, x_t.shape)\n        posterior_log_variance_clipped = extract_into_tensor(self.posterior_log_variance_clipped, t, x_t.shape)\n        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n    def p_mean_variance(self, x, t, clip_denoised: bool):"
        },
        {
            "comment": "The model calculates the mean, variance, and log variance for the prior distribution using `p_mean_variance` function. It then generates noise and applies a mask to calculate the final sample using `p_sample`. The `p_sample_loop` function is an optimized version of `p_sample` with the option to return intermediate results.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":242-263",
            "content": "        model_out = self.model(x, t)\n        if self.parameterization == \"eps\":\n            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n        elif self.parameterization == \"x0\":\n            x_recon = model_out\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n        return model_mean, posterior_variance, posterior_log_variance\n    @torch.no_grad()\n    def p_sample(self, x, t, clip_denoised=True, repeat_noise=False):\n        b, *_, device = *x.shape, x.device\n        model_mean, _, model_log_variance = self.p_mean_variance(x=x, t=t, clip_denoised=clip_denoised)\n        noise = noise_like(x.shape, device, repeat_noise)\n        # no noise when t == 0\n        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n    @torch.no_grad()\n    def p_sample_loop(self, shape, return_intermediates=False):"
        },
        {
            "comment": "This code defines a model that samples images from a diffusion process, with the ability to return intermediate frames if desired. It uses PyTorch and has a `sample` method for generating images and a `q_sample` method for querying sample states at specific timesteps. The code also includes a `p_sample_loop` function which iterates over timesteps in reverse order to generate the image frames.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":264-285",
            "content": "        device = self.betas.device\n        b = shape[0]\n        img = torch.randn(shape, device=device)\n        intermediates = [img]\n        for i in tqdm(reversed(range(0, self.num_timesteps)), desc='Sampling t', total=self.num_timesteps):\n            img = self.p_sample(img, torch.full((b,), i, device=device, dtype=torch.long),\n                                clip_denoised=self.clip_denoised)\n            if i % self.log_every_t == 0 or i == self.num_timesteps - 1:\n                intermediates.append(img)\n        if return_intermediates:\n            return img, intermediates\n        return img\n    @torch.no_grad()\n    def sample(self, batch_size=16, return_intermediates=False):\n        image_size = self.image_size\n        channels = self.channels\n        return self.p_sample_loop((batch_size, channels, image_size, image_size),\n                                  return_intermediates=return_intermediates)\n    def q_sample(self, x_start, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))"
        },
        {
            "comment": "The code defines various methods for handling and manipulating images. The `get_v` method calculates a value used in denoising, the `get_input` method prepares input data, `_get_rows_from_list` rearranges samples into grids with specified number of rows, and `log_images` logs images from batch data.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":286-310",
            "content": "        return (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise)\n    def get_v(self, x, noise, t):\n        return (\n                extract_into_tensor(self.sqrt_alphas_cumprod, t, x.shape) * noise -\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x.shape) * x\n        )\n    def get_input(self, batch, k):\n        x = batch[k]\n        x = x.to(memory_format=torch.contiguous_format).float()\n        return x\n    def _get_rows_from_list(self, samples):\n        n_imgs_per_row = len(samples)\n        denoise_grid = rearrange(samples, 'n b c h w -> b n c h w')\n        denoise_grid = rearrange(denoise_grid, 'b n c h w -> (b n) c h w')\n        denoise_grid = make_grid(denoise_grid, nrow=n_imgs_per_row)\n        return denoise_grid\n    @torch.no_grad()\n    def log_images(self, batch, N=8, n_row=2, sample=True, return_keys=None, **kwargs):\n        log = dict()\n        x = self.get_input(batch, self.first_stage_key)"
        },
        {
            "comment": "This code performs diffusion modeling and denoising. It first checks the number of input samples and rows, then iterates through each timestep to generate noisy versions of the inputs. If sampling is enabled, it also generates denoised rows. The generated results are stored in a log dictionary for further use.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":311-339",
            "content": "        N = min(x.shape[0], N)\n        n_row = min(x.shape[0], n_row)\n        x = x.to(self.device)[:N]\n        log[\"inputs\"] = x\n        # get diffusion row\n        diffusion_row = list()\n        x_start = x[:n_row]\n        for t in range(self.num_timesteps):\n            if t % self.log_every_t == 0 or t == self.num_timesteps - 1:\n                t = repeat(torch.tensor([t]), '1 -> b', b=n_row)\n                t = t.to(self.device).long()\n                noise = torch.randn_like(x_start)\n                x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n                diffusion_row.append(x_noisy)\n        log[\"diffusion_row\"] = self._get_rows_from_list(diffusion_row)\n        if sample:\n            # get denoise row\n            with self.ema_scope(\"Plotting\"):\n                samples, denoise_row = self.sample(batch_size=N, return_intermediates=True)\n            log[\"samples\"] = samples\n            log[\"denoise_row\"] = self._get_rows_from_list(denoise_row)\n        if return_keys:\n            if np.intersect1d(list(log.keys()), return_keys).shape[0] == 0:"
        },
        {
            "comment": "This code defines the LatentDiffusion class that extends the DDPM class and takes in various configuration parameters for different stages of the model. The LatentDiffusion class has methods to train and save the model, as well as initialize the internal components based on the given configurations.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":340-370",
            "content": "                return log\n            else:\n                return {key: log[key] for key in return_keys}\n        return log\nclass LatentDiffusion(DDPM):\n    \"\"\"main class\"\"\"\n    def __init__(self,\n                 first_stage_config,\n                 cond_stage_config,\n                 num_timesteps_cond=None,\n                 cond_stage_key=\"caption\",\n                 cond_stage_trainable=False,\n                 cond_stage_forward=None,\n                 conditioning_key=None,\n                 uncond_prob=0.2,\n                 uncond_type=\"empty_seq\",\n                 scale_factor=1.0,\n                 scale_by_std=False,\n                 encoder_type=\"2d\",\n                 only_model=False,\n                 noise_strength=0,\n                 use_dynamic_rescale=False,\n                 base_scale=0.7,\n                 turning_step=400,\n                 loop_video=False,\n                 *args, **kwargs):\n        self.num_timesteps_cond = default(num_timesteps_cond, 1)\n        self.scale_by_std = scale_by_std\n        assert self.num_timesteps_cond <= kwargs['timesteps']"
        },
        {
            "comment": "Code initializes DDPM3D model with optional parameters such as ckpt_path, ignore_keys, conditioning_key, and more. It also determines the number of downsampling stages based on config and sets scale_factor if not using dynamic rescale.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":371-393",
            "content": "        # for backwards compatibility after implementation of DiffusionWrapper\n        ckpt_path = kwargs.pop(\"ckpt_path\", None)\n        ignore_keys = kwargs.pop(\"ignore_keys\", [])\n        conditioning_key = default(conditioning_key, 'crossattn')\n        super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n        self.cond_stage_trainable = cond_stage_trainable\n        self.cond_stage_key = cond_stage_key\n        self.noise_strength = noise_strength\n        self.use_dynamic_rescale = use_dynamic_rescale\n        self.loop_video = loop_video\n        try:\n            self.num_downs = len(first_stage_config.params.ddconfig.ch_mult) - 1\n        except:\n            self.num_downs = 0\n        if not scale_by_std:\n            self.scale_factor = scale_factor\n        else:\n            self.register_buffer('scale_factor', torch.tensor(scale_factor))\n        if use_dynamic_rescale:\n            scale_arr1 = np.linspace(1.0, base_scale, turning_step)\n            scale_arr2 = np.full(self.num_timesteps, base_scale)"
        },
        {
            "comment": "Instantiate first and conditional stages, set configuration parameters, and initialize buffers. Verify encoder type and unconditional type. Allow restarting from checkpoint if provided path is not None.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":394-418",
            "content": "            scale_arr = np.concatenate((scale_arr1, scale_arr2))\n            to_torch = partial(torch.tensor, dtype=torch.float32)\n            self.register_buffer('scale_arr', to_torch(scale_arr))\n        self.instantiate_first_stage(first_stage_config)\n        self.instantiate_cond_stage(cond_stage_config)\n        self.first_stage_config = first_stage_config\n        self.cond_stage_config = cond_stage_config        \n        self.clip_denoised = False\n        self.cond_stage_forward = cond_stage_forward\n        self.encoder_type = encoder_type\n        assert(encoder_type in [\"2d\", \"3d\"])\n        self.uncond_prob = uncond_prob\n        self.classifier_free_guidance = True if uncond_prob > 0 else False\n        assert(uncond_type in [\"zero_embed\", \"empty_seq\"])\n        self.uncond_type = uncond_type\n        self.restarted_from_ckpt = False\n        if ckpt_path is not None:\n            self.init_from_ckpt(ckpt_path, ignore_keys, only_model=only_model)\n            self.restarted_from_ckpt = True\n    def make_cond_schedule(self, ):"
        },
        {
            "comment": "This code initializes the conditional stages of a diffusion model. It assigns the conditioning IDs for timesteps, instantiates the first stage model with disabled gradients and fixed parameters, and then conditionally instantiates the second (conditional) stage model either with a fixed or trainable configuration depending on the `cond_stage_trainable` flag. The fixed models are used for evaluation, while the trainable one is for training.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":419-439",
            "content": "        self.cond_ids = torch.full(size=(self.num_timesteps,), fill_value=self.num_timesteps - 1, dtype=torch.long)\n        ids = torch.round(torch.linspace(0, self.num_timesteps - 1, self.num_timesteps_cond)).long()\n        self.cond_ids[:self.num_timesteps_cond] = ids\n    def instantiate_first_stage(self, config):\n        model = instantiate_from_config(config)\n        self.first_stage_model = model.eval()\n        self.first_stage_model.train = disabled_train\n        for param in self.first_stage_model.parameters():\n            param.requires_grad = False\n    def instantiate_cond_stage(self, config):\n        if not self.cond_stage_trainable:\n            model = instantiate_from_config(config)\n            self.cond_stage_model = model.eval()\n            self.cond_stage_model.train = disabled_train\n            for param in self.cond_stage_model.parameters():\n                param.requires_grad = False\n        else:\n            model = instantiate_from_config(config)\n            self.cond_stage_model = model"
        },
        {
            "comment": "The code defines two methods: 'get_learned_conditioning' and 'get_first_stage_encoding'. The first method retrieves the learned conditioning from a model, possibly encoding it if the model has an 'encode' function. It also handles the case where the model does not have the necessary functions and returns the input unchanged or applies the model directly to the input. The second method takes an encoder_posterior (encoder posterior) as input and returns the first stage encoding, handling DiagonalGaussianDistribution, torch.Tensor, and other types of encoder_posterior inputs appropriately.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":441-461",
            "content": "    def get_learned_conditioning(self, c):\n        if self.cond_stage_forward is None:\n            if hasattr(self.cond_stage_model, 'encode') and callable(self.cond_stage_model.encode):\n                c = self.cond_stage_model.encode(c)\n                if isinstance(c, DiagonalGaussianDistribution):\n                    c = c.mode()\n            else:\n                c = self.cond_stage_model(c)\n        else:\n            assert hasattr(self.cond_stage_model, self.cond_stage_forward)\n            c = getattr(self.cond_stage_model, self.cond_stage_forward)(c)\n        return c\n    def get_first_stage_encoding(self, encoder_posterior, noise=None):\n        if isinstance(encoder_posterior, DiagonalGaussianDistribution):\n            z = encoder_posterior.sample(noise=noise)\n        elif isinstance(encoder_posterior, torch.Tensor):\n            z = encoder_posterior\n        else:\n            raise NotImplementedError(f\"encoder_posterior of type '{type(encoder_posterior)}' not yet implemented\")\n        return self.scale_factor * z"
        },
        {
            "comment": "This code defines two functions: `encode_first_stage` and `decode_core`. The first function encodes an input tensor using a first-stage model and may perform reshaping operations based on the tensor's shape. The second function decodes a tensor using the same first-stage model, also potentially reshaping it before or after the decoding process. Both functions consider the tensor's dimensionality and apply reshaping if needed.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":463-494",
            "content": "    @torch.no_grad()\n    def encode_first_stage(self, x):\n        if self.encoder_type == \"2d\" and x.dim() == 5:\n            b, _, t, _, _ = x.shape\n            x = rearrange(x, 'b c t h w -> (b t) c h w')\n            reshape_back = True\n        else:\n            reshape_back = False\n        encoder_posterior = self.first_stage_model.encode(x)\n        results = self.get_first_stage_encoding(encoder_posterior).detach()\n        if reshape_back:\n            results = rearrange(results, '(b t) c h w -> b c t h w', b=b,t=t)\n        return results\n    def decode_core(self, z, **kwargs):\n        if self.encoder_type == \"2d\" and z.dim() == 5:\n            b, _, t, _, _ = z.shape\n            z = rearrange(z, 'b c t h w -> (b t) c h w')\n            reshape_back = True\n        else:\n            reshape_back = False\n        z = 1. / self.scale_factor * z\n        results = self.first_stage_model.decode(z, **kwargs)\n        if reshape_back:\n            results = rearrange(results, '(b t) c h w -> b c t h w', b=b,t=t)\n        return results"
        },
        {
            "comment": "The code defines a function that takes in noisy input (x_noisy) and a timestep (t), as well as some conditioning information (cond). It applies the model to generate reconstructed output (x_recon). If cond is a dictionary, it does something specific. The model returns either a single output or a tuple of outputs.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":496-523",
            "content": "    @torch.no_grad()\n    def decode_first_stage(self, z, **kwargs):\n        return self.decode_core(z, **kwargs)\n    # same as above but without decorator\n    def differentiable_decode_first_stage(self, z, **kwargs):\n        return self.decode_core(z, **kwargs)\n    def forward(self, x, c, **kwargs):\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n        if self.use_dynamic_rescale:\n            x = x * extract_into_tensor(self.scale_arr, t, x.shape)\n        return self.p_losses(x, c, t, **kwargs)\n    def apply_model(self, x_noisy, t, cond, **kwargs):\n        if isinstance(cond, dict):\n            # hybrid case, cond is exptected to be a dict\n            pass\n        else:\n            if not isinstance(cond, list):\n                cond = [cond]\n            key = 'c_concat' if self.model.conditioning_key == 'concat' else 'c_crossattn'\n            cond = {key: cond}\n        x_recon = self.model(x_noisy, t, **cond, **kwargs)\n        if isinstance(x_recon, tuple):\n            return x_recon[0]"
        },
        {
            "comment": "This function, `_get_denoise_row_from_list`, takes a list of samples and denoises them using the first-stage decoder. It then rearranges the data into a grid format based on the number of timesteps and batch size. If there are 5 dimensions (timesteps, batch, channels, height, width), it is reshaped into a 2D grid. If there are 6 dimensions (timesteps, batch, channels, time, height, width), it is reshaped into a 3D grid suitable for video visualization. The rearranged data is then displayed as a grid using `make_grid` function.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":524-545",
            "content": "        else:\n            return x_recon\n    def _get_denoise_row_from_list(self, samples, desc=''):\n        denoise_row = []\n        for zd in tqdm(samples, desc=desc):\n            denoise_row.append(self.decode_first_stage(zd.to(self.device)))\n        n_log_timesteps = len(denoise_row)\n        denoise_row = torch.stack(denoise_row)  # n_log_timesteps, b, C, H, W\n        if denoise_row.dim() == 5:\n            denoise_grid = rearrange(denoise_row, 'n b c h w -> b n c h w')\n            denoise_grid = rearrange(denoise_grid, 'b n c h w -> (b n) c h w')\n            denoise_grid = make_grid(denoise_grid, nrow=n_log_timesteps)\n        elif denoise_row.dim() == 6:\n            # video, grid_size=[n_log_timesteps*bs, t]\n            video_length = denoise_row.shape[3]\n            denoise_grid = rearrange(denoise_row, 'n b c t h w -> b n c t h w')\n            denoise_grid = rearrange(denoise_grid, 'b n c t h w -> (b n) c t h w')\n            denoise_grid = rearrange(denoise_grid, 'n c t h w -> (n t) c h w')\n            denoise_grid = make_grid(denoise_grid, nrow=video_length)"
        },
        {
            "comment": "This code defines a function that calculates the mean and variance of the data for a denoising diffusion probability model (DDPM). The function takes in an input image 'x', conditioning information 'c', time step 't', and other parameters. If the parameterization is set to \"eps\" or \"x0\", it reconstructs the image from noise and calculates the mean and variance. If the image needs to be denoised, it clamps the values between -1 and 1. If return_x0 is True, it returns the mean, variance, and log variance along with the original input image.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":546-575",
            "content": "        else:\n            raise ValueError\n        return denoise_grid\n    def p_mean_variance(self, x, c, t, clip_denoised: bool, return_x0=False, score_corrector=None, corrector_kwargs=None, **kwargs):\n        t_in = t\n        model_out = self.apply_model(x, t_in, c, **kwargs)\n        if score_corrector is not None:\n            assert self.parameterization == \"eps\"\n            model_out = score_corrector.modify_score(self, model_out, x, t, c, **corrector_kwargs)\n        if self.parameterization == \"eps\":\n            x_recon = self.predict_start_from_noise(x, t=t, noise=model_out)\n        elif self.parameterization == \"x0\":\n            x_recon = model_out\n        else:\n            raise NotImplementedError()\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n        if return_x0:\n            return model_mean, posterior_variance, posterior_log_variance, x_recon\n        else:\n            return model_mean, posterior_variance, posterior_log_variance"
        },
        {
            "comment": "This code defines a `p_sample` function that takes input `x`, condition `c`, and time step `t`. It computes mean and variance from the model, applies noise based on temperature and dropout rate, and combines them to generate samples. The output is either the denoised sample and original input (`return_x0=True`) or just the denoised sample (`return_x0=False`).",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":577-595",
            "content": "    @torch.no_grad()\n    def p_sample(self, x, c, t, clip_denoised=False, repeat_noise=False, return_x0=False, \\\n                 temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None, **kwargs):\n        b, *_, device = *x.shape, x.device\n        outputs = self.p_mean_variance(x=x, c=c, t=t, clip_denoised=clip_denoised, return_x0=return_x0, \\\n                                       score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, **kwargs)\n        if return_x0:\n            model_mean, _, model_log_variance, x0 = outputs\n        else:\n            model_mean, _, model_log_variance = outputs\n        noise = noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout > 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        # no noise when t == 0\n        nonzero_mask = (1 - (t == 0).float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n        if return_x0:\n            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise, x0"
        },
        {
            "comment": "This function samples an initial noise and iteratively updates it to generate images at different timesteps. It returns intermediate outputs if requested. The code also checks for the presence of timesteps, start_T, and log_every_t parameters, and handles them accordingly. The function uses a tqdm progress bar for verbose output during sampling.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":596-623",
            "content": "        else:\n            return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n    @torch.no_grad()\n    def p_sample_loop(self, cond, shape, return_intermediates=False, x_T=None, verbose=True, callback=None, \\\n                      timesteps=None, mask=None, x0=None, img_callback=None, start_T=None, log_every_t=None, **kwargs):\n        if not log_every_t:\n            log_every_t = self.log_every_t\n        device = self.betas.device\n        b = shape[0]        \n        # sample an initial noise\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n        intermediates = [img]\n        if timesteps is None:\n            timesteps = self.num_timesteps\n        if start_T is not None:\n            timesteps = min(timesteps, start_T)\n        iterator = tqdm(reversed(range(0, timesteps)), desc='Sampling t', total=timesteps) if verbose else reversed(range(0, timesteps))\n        if mask is not None:\n            assert x0 is not None\n            assert x0.shape[2:3] == mask.shape[2:3]  # spatial size has to match"
        },
        {
            "comment": "This code iterates over a range of timesteps, for each timestep it generates an image, optionally applies masking to the generated image and appends it to intermediates list. The method also updates the conditional input for the model at each timestep, clips the denoised image if necessary, and calls callback functions after each iteration. If return_intermediates is True, it returns the final image and a list of intermediate images; otherwise, it only returns the final image. The LatentVisualDiffusion class initializes the LatentDiffusion base class with specified configuration for image conditioning and projection stages.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":625-649",
            "content": "        for i in iterator:\n            ts = torch.full((b,), i, device=device, dtype=torch.long)\n            if self.shorten_cond_schedule:\n                assert self.model.conditioning_key != 'hybrid'\n                tc = self.cond_ids[ts].to(cond.device)\n                cond = self.q_sample(x_start=cond, t=tc, noise=torch.randn_like(cond))\n            img = self.p_sample(img, cond, ts, clip_denoised=self.clip_denoised, **kwargs)\n            if mask is not None:\n                img_orig = self.q_sample(x0, ts)\n                img = img_orig * mask + (1. - mask) * img\n            if i % log_every_t == 0 or i == timesteps - 1:\n                intermediates.append(img)\n            if callback: callback(i)\n            if img_callback: img_callback(img, i)\n        if return_intermediates:\n            return img, intermediates\n        return img\nclass LatentVisualDiffusion(LatentDiffusion):\n    def __init__(self, img_cond_stage_config, image_proj_stage_config, freeze_embedder=True, *args, **kwargs):\n        super().__init__(*args, **kwargs)"
        },
        {
            "comment": "This code initializes an embedder and sets up the DiffusionWrapper class. The _init_embedder function initializes an embedder model, freezing its parameters if specified. The DiffusionWrapper class is a LightningModule that takes a diffusion model configuration and a conditioning key (concat or other). If no conditioning key is provided, it directly passes data through the diffusion model; otherwise, it performs conditioning operations before passing the data.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":650-673",
            "content": "        self._init_embedder(img_cond_stage_config, freeze_embedder)\n        self.image_proj_model = instantiate_from_config(image_proj_stage_config)\n    def _init_embedder(self, config, freeze=True):\n        embedder = instantiate_from_config(config)\n        if freeze:\n            self.embedder = embedder.eval()\n            self.embedder.train = disabled_train\n            for param in self.embedder.parameters():\n                param.requires_grad = False\nclass DiffusionWrapper(pl.LightningModule):\n    def __init__(self, diff_model_config, conditioning_key):\n        super().__init__()\n        self.diffusion_model = instantiate_from_config(diff_model_config)\n        self.conditioning_key = conditioning_key\n    def forward(self, x, t, c_concat: list = None, c_crossattn: list = None,\n                c_adm=None, s=None, mask=None, **kwargs):\n        # temporal_context = fps is foNone\n        if self.conditioning_key is None:\n            out = self.diffusion_model(x, t)\n        elif self.conditioning_key == 'concat':"
        },
        {
            "comment": "The code above contains conditional branches for different conditioning methods, such as hybrid, crossattn, resblockcond, adm, and hybrid-adm. It concatenates the input (x) with other tensors based on the conditioning key, and then passes the resulting tensor to the diffusion model for processing. The output of the model is stored in 'out'.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":674-694",
            "content": "            xc = torch.cat([x] + c_concat, dim=1)\n            out = self.diffusion_model(xc, t, **kwargs)\n        elif self.conditioning_key == 'crossattn':\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(x, t, context=cc, **kwargs)\n        elif self.conditioning_key == 'hybrid':\n            ## it is just right [b,c,t,h,w]: concatenate in channel dim\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc, **kwargs)\n        elif self.conditioning_key == 'resblockcond':\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, context=cc)\n        elif self.conditioning_key == 'adm':\n            cc = c_crossattn[0]\n            out = self.diffusion_model(x, t, y=cc)\n        elif self.conditioning_key == 'hybrid-adm':\n            assert c_adm is not None\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc, y=c_adm, **kwargs)"
        },
        {
            "comment": "This code block handles various conditioning methods for the diffusion model. It uses different combinations of inputs such as x, c_concat, t, s, and mask based on the specified conditioning key. The keys include 'hybrid-time', 'concat-time-mask', 'concat-adm-mask', and 'hybrid-adm-mask'. Each block performs specific operations and asserts before passing the data to self.diffusion_model for further processing.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":695-717",
            "content": "        elif self.conditioning_key == 'hybrid-time':\n            assert s is not None\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc, s=s)\n        elif self.conditioning_key == 'concat-time-mask':\n            # assert s is not None\n            xc = torch.cat([x] + c_concat, dim=1)\n            out = self.diffusion_model(xc, t, context=None, s=s, mask=mask)\n        elif self.conditioning_key == 'concat-adm-mask':\n            # assert s is not None\n            if c_concat is not None:\n                xc = torch.cat([x] + c_concat, dim=1)\n            else:\n                xc = x\n            out = self.diffusion_model(xc, t, context=None, y=s, mask=mask)\n        elif self.conditioning_key == 'hybrid-adm-mask':\n            cc = torch.cat(c_crossattn, 1)\n            if c_concat is not None:\n                xc = torch.cat([x] + c_concat, dim=1)\n            else:\n                xc = x\n            out = self.diffusion_model(xc, t, context=cc, y=s, mask=mask)"
        },
        {
            "comment": "Code handles different conditioning keys for model inputs. If 'hybrid-time-adm' key, concatenates x and c_concat along dimension 1, then passes to diffusion model with context cc, s, and c_adm. If 'crossattn-adm' key, only concatenates c_crossattn along dimension 1 before passing to diffusion model with y as c_adm. For other keys, raises NotImplementedError.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/ddpm3d.py\":718-731",
            "content": "        elif self.conditioning_key == 'hybrid-time-adm': # adm means y, e.g., class index\n            # assert s is not None\n            assert c_adm is not None\n            xc = torch.cat([x] + c_concat, dim=1)\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(xc, t, context=cc, s=s, y=c_adm)\n        elif self.conditioning_key == 'crossattn-adm':\n            assert c_adm is not None\n            cc = torch.cat(c_crossattn, 1)\n            out = self.diffusion_model(x, t, context=cc, y=c_adm)\n        else:\n            raise NotImplementedError()\n        return out"
        }
    ]
}