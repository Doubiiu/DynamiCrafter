{
    "summary": "The code defines a resampler module with 8 layers, layer normalization, and linear transforms for the DynamiCrafter/lvdm project. It includes PerceiverAttention and FeedForward layers in its forward function to process input latents and apply projection and normalization.",
    "details": [
        {
            "comment": "This code defines an ImageProjModel class that performs projection for cross-attention. It has a linear projection layer and a layer normalization layer. The model takes image embeddings as input, reshapes them based on the number of clip_extra_context_tokens and the dimension of cross_attention_dim.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/modules/encoders/resampler.py\":0-20",
            "content": "# modified from https://github.com/mlfoundations/open_flamingo/blob/main/open_flamingo/src/helpers.py\n# and https://github.com/lucidrains/imagen-pytorch/blob/main/imagen_pytorch/imagen_pytorch.py\n# and https://github.com/tencent-ailab/IP-Adapter/blob/main/ip_adapter/resampler.py\nimport math\nimport torch\nimport torch.nn as nn\nclass ImageProjModel(nn.Module):\n    \"\"\"Projection Model\"\"\"\n    def __init__(self, cross_attention_dim=1024, clip_embeddings_dim=1024, clip_extra_context_tokens=4):\n        super().__init__()        \n        self.cross_attention_dim = cross_attention_dim\n        self.clip_extra_context_tokens = clip_extra_context_tokens\n        self.proj = nn.Linear(clip_embeddings_dim, self.clip_extra_context_tokens * cross_attention_dim)\n        self.norm = nn.LayerNorm(cross_attention_dim)\n    def forward(self, image_embeds):\n        #embeds = image_embeds\n        embeds = image_embeds.type(list(self.proj.parameters())[0].dtype)\n        clip_extra_context_tokens = self.proj(embeds).reshape(-1, self.clip_extra_context_tokens, self.cross_attention_dim)"
        },
        {
            "comment": "The code defines a PerceiverAttention class that performs self-attention in the context of a deep learning model. It includes methods for applying a feed-forward layer (FeedForward) and reshaping tensors (reshape_tensor). The class has attributes like dimension, number of heads, and hidden dimension for attention calculations. It also initializes a LayerNorm and contains normalization steps to ensure stability and efficiency in the computations.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/modules/encoders/resampler.py\":21-55",
            "content": "        clip_extra_context_tokens = self.norm(clip_extra_context_tokens)\n        return clip_extra_context_tokens\n# FFN\ndef FeedForward(dim, mult=4):\n    inner_dim = int(dim * mult)\n    return nn.Sequential(\n        nn.LayerNorm(dim),\n        nn.Linear(dim, inner_dim, bias=False),\n        nn.GELU(),\n        nn.Linear(inner_dim, dim, bias=False),\n    )\ndef reshape_tensor(x, heads):\n    bs, length, width = x.shape\n    #(bs, length, width) --> (bs, length, n_heads, dim_per_head)\n    x = x.view(bs, length, heads, -1)\n    # (bs, length, n_heads, dim_per_head) --> (bs, n_heads, length, dim_per_head)\n    x = x.transpose(1, 2)\n    # (bs, n_heads, length, dim_per_head) --> (bs*n_heads, length, dim_per_head)\n    x = x.reshape(bs, heads, length, -1)\n    return x\nclass PerceiverAttention(nn.Module):\n    def __init__(self, *, dim, dim_head=64, heads=8):\n        super().__init__()\n        self.scale = dim_head**-0.5\n        self.dim_head = dim_head\n        self.heads = heads\n        inner_dim = dim_head * heads\n        self.norm1 = nn.LayerNorm(dim)"
        },
        {
            "comment": "This code defines a Resampler class with layer normalization and linear transforms. The forward function takes image features (x) and latent features (latents) as inputs, applies normalization, performs attention mechanism using the input tensors, and returns the weighted output.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/modules/encoders/resampler.py\":56-87",
            "content": "        self.norm2 = nn.LayerNorm(dim)\n        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n        self.to_kv = nn.Linear(dim, inner_dim * 2, bias=False)\n        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n    def forward(self, x, latents):\n        \"\"\"\n        Args:\n            x (torch.Tensor): image features\n                shape (b, n1, D)\n            latent (torch.Tensor): latent features\n                shape (b, n2, D)\n        \"\"\"\n        x = self.norm1(x)\n        latents = self.norm2(latents)\n        b, l, _ = latents.shape\n        q = self.to_q(latents)\n        kv_input = torch.cat((x, latents), dim=-2)\n        k, v = self.to_kv(kv_input).chunk(2, dim=-1)\n        q = reshape_tensor(q, self.heads)\n        k = reshape_tensor(k, self.heads)\n        v = reshape_tensor(v, self.heads)\n        # attention\n        scale = 1 / math.sqrt(math.sqrt(self.dim_head))\n        weight = (q * scale) @ (k * scale).transpose(-2, -1) # More stable with f16 than dividing afterwards\n        weight = torch.softmax(weight.float(), dim=-1).type(weight.dtype)"
        },
        {
            "comment": "The Resampler class is a neural network module that takes in an embedding dimension of 768, outputs a dimension of 1024. It has a depth of 8 and utilizes a specified number of queries for each frame or image depending on whether video length is provided or not. It also contains linear projections (proj_in, proj_out), a layer normalization (norm_out) and a series of layers (self.layers). This Resampler class seems to be part of a larger model that processes and resamples data for various purposes.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/modules/encoders/resampler.py\":88-124",
            "content": "        out = weight @ v\n        out = out.permute(0, 2, 1, 3).reshape(b, l, -1)\n        return self.to_out(out)\nclass Resampler(nn.Module):\n    def __init__(\n        self,\n        dim=1024,\n        depth=8,\n        dim_head=64,\n        heads=16,\n        num_queries=8,\n        embedding_dim=768,\n        output_dim=1024,\n        ff_mult=4,\n        video_length=None, # using frame-wise version or not\n    ):\n        super().__init__()\n        ## queries for a single frame / image\n        self.num_queries = num_queries \n        self.video_length = video_length\n        ## <num_queries> queries for each frame\n        if video_length is not None: \n            num_queries = num_queries * video_length\n        self.latents = nn.Parameter(torch.randn(1, num_queries, dim) / dim**0.5)\n        self.proj_in = nn.Linear(embedding_dim, dim)\n        self.proj_out = nn.Linear(dim, output_dim)\n        self.norm_out = nn.LayerNorm(output_dim)\n        self.layers = nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append("
        },
        {
            "comment": "This code defines a resampler module for the DynamiCrafter/lvdm project. It uses PerceiverAttention and FeedForward layers in its forward function, which repeats input latents, processes them through layers, applies projection and normalization, and returns the result.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/modules/encoders/resampler.py\":125-144",
            "content": "                nn.ModuleList(\n                    [\n                        PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n                        FeedForward(dim=dim, mult=ff_mult),\n                    ]\n                )\n            )\n    def forward(self, x):\n        latents = self.latents.repeat(x.size(0), 1, 1) ## B (T L) C\n        x = self.proj_in(x)\n        for attn, ff in self.layers:\n            latents = attn(x, latents) + latents\n            latents = ff(latents) + latents\n        latents = self.proj_out(latents)\n        latents = self.norm_out(latents) # B L C or B (T L) C\n        return latents"
        }
    ]
}