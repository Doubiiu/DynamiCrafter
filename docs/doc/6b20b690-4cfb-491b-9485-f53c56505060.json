{
    "summary": "The DDIMSampler class in PyTorch implements both DDPM and DDIM sampling, handles timesteps, and is used for image generation with input conditioning and optional parameters. It applies the model to generate e_t, combines values, transforms based on parameterization type, and performs DDIM sampling using denoising and fast reconstruction functions.",
    "details": [
        {
            "comment": "DDIMSampler class is being initialized with a model, schedule and other parameters. It has methods to make scheduling based on given steps, register buffers for tensor attributes, and uses make_ddim_timesteps function from lvdm.utils_diffusion module. This code seems to be part of a larger diffusion model that utilizes DDIM sampling.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":0-24",
            "content": "import numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom lvdm.models.utils_diffusion import make_ddim_sampling_parameters, make_ddim_timesteps\nfrom lvdm.common import noise_like\nfrom lvdm.common import extract_into_tensor\nclass DDIMSampler(object):\n    def __init__(self, model, schedule=\"linear\", **kwargs):\n        super().__init__()\n        self.model = model\n        self.ddpm_num_timesteps = model.num_timesteps\n        self.schedule = schedule\n        self.counter = 0\n    def register_buffer(self, name, attr):\n        if type(attr) == torch.Tensor:\n            if attr.device != torch.device(\"cuda\"):\n                attr = attr.to(torch.device(\"cuda\"))\n        setattr(self, name, attr)\n    def make_schedule(self, ddim_num_steps, ddim_discretize=\"uniform\", ddim_eta=0., verbose=True):\n        self.ddim_timesteps = make_ddim_timesteps(ddim_discr_method=ddim_discretize, num_ddim_timesteps=ddim_num_steps,\n                                                  num_ddpm_timesteps=self.ddpm_num_timesteps,verbose=verbose)"
        },
        {
            "comment": "This code is initializing various buffers for a diffusion model. It assigns the alphas_cumprod to a buffer, asserts that its shape matches the number of timesteps, converts tensors to float32 type and moves them to the device, registers buffers for betas, alphas_cumprod, alphas_cumprod_prev, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, and log_one_minus_alphas_cumprod. This model is used in a diffusion process to calculate q(x_t | x_{t-1}) and other related calculations.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":25-40",
            "content": "        alphas_cumprod = self.model.alphas_cumprod\n        assert alphas_cumprod.shape[0] == self.ddpm_num_timesteps, 'alphas have to be defined for each timestep'\n        to_torch = lambda x: x.clone().detach().to(torch.float32).to(self.model.device)\n        if self.model.use_dynamic_rescale:\n            self.ddim_scale_arr = self.model.scale_arr[self.ddim_timesteps]\n            self.ddim_scale_arr_prev = torch.cat([self.ddim_scale_arr[0:1], self.ddim_scale_arr[:-1]])\n        self.register_buffer('betas', to_torch(self.model.betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(self.model.alphas_cumprod_prev))\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod.cpu())))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod.cpu())))"
        },
        {
            "comment": "The code registers buffers for DDIM sampling parameters and calculates sigmas_for_original_sampling_steps. It initializes ddim_sigmas, ddim_alphas, ddim_alphas_prev, and ddim_sqrt_one_minus_alphas. The alphas_cumprod is computed from the input alphas_cumprod and alphas_cumprod_prev is also calculated. Sigmas for original sampling steps are determined based on these parameters. This code implements DDIM (Denoising Diffusion Probabilistic Models) sampling technique in PyTorch.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":41-54",
            "content": "        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu() - 1)))\n        # ddim sampling parameters\n        ddim_sigmas, ddim_alphas, ddim_alphas_prev = make_ddim_sampling_parameters(alphacums=alphas_cumprod.cpu(),\n                                                                                   ddim_timesteps=self.ddim_timesteps,\n                                                                                   eta=ddim_eta,verbose=verbose)\n        self.register_buffer('ddim_sigmas', ddim_sigmas)\n        self.register_buffer('ddim_alphas', ddim_alphas)\n        self.register_buffer('ddim_alphas_prev', ddim_alphas_prev)\n        self.register_buffer('ddim_sqrt_one_minus_alphas', np.sqrt(1. - ddim_alphas))\n        sigmas_for_original_sampling_steps = ddim_eta * torch.sqrt(\n            (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod) * (\n                        1 - self.alphas_cumprod / self.alphas_cumprod_prev))"
        },
        {
            "comment": "This code defines a DDPM (Denoising Diffusion Probabilistic Models) sampler class with a sample method. The sample method takes input S, batch_size, shape, and other optional parameters to generate samples from the model. It also has methods for registering buffer and various options for controlling the sampling process.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":55-86",
            "content": "        self.register_buffer('ddim_sigmas_for_original_num_steps', sigmas_for_original_sampling_steps)\n    @torch.no_grad()\n    def sample(self,\n               S,\n               batch_size,\n               shape,\n               conditioning=None,\n               callback=None,\n               normals_sequence=None,\n               img_callback=None,\n               quantize_x0=False,\n               eta=0.,\n               mask=None,\n               x0=None,\n               temperature=1.,\n               noise_dropout=0.,\n               score_corrector=None,\n               corrector_kwargs=None,\n               verbose=True,\n               schedule_verbose=False,\n               x_T=None,\n               log_every_t=100,\n               unconditional_guidance_scale=1.,\n               unconditional_conditioning=None,\n               precision=None,\n               fs=None,\n               # this has to come in the same format as the conditioning, # e.g. as encoded tokens, ...\n               **kwargs\n               ):\n        # check condition bs"
        },
        {
            "comment": "Checks if conditioning is provided, ensures its shape matches the batch size. Sets up the sampling schedule, determines data shape based on input shape, and then performs DDIM sampling.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":87-111",
            "content": "        if conditioning is not None:\n            if isinstance(conditioning, dict):\n                try:\n                    cbs = conditioning[list(conditioning.keys())[0]].shape[0]\n                except:\n                    cbs = conditioning[list(conditioning.keys())[0]][0].shape[0]\n                if cbs != batch_size:\n                    print(f\"Warning: Got {cbs} conditionings but batch-size is {batch_size}\")\n            else:\n                if conditioning.shape[0] != batch_size:\n                    print(f\"Warning: Got {conditioning.shape[0]} conditionings but batch-size is {batch_size}\")\n        self.make_schedule(ddim_num_steps=S, ddim_eta=eta, verbose=schedule_verbose)\n        # make shape\n        if len(shape) == 3:\n            C, H, W = shape\n            size = (batch_size, C, H, W)\n        elif len(shape) == 4:\n            C, T, H, W = shape\n            size = (batch_size, C, T, H, W)\n        # print(f'Data shape for DDIM sampling is {size}, eta {eta}')\n        samples, intermediates = self.ddim_sampling(conditioning, size,"
        },
        {
            "comment": "This code block defines a function that takes in parameters such as callback, img_callback, quantize_denoised, mask, x0, ddim_use_original_steps, noise_dropout, temperature, score_corrector, corrector_kwargs, x_T, log_every_t, unconditional_guidance_scale, and unconditional_conditioning. It uses these parameters to perform denoising diffusion probabilistic sampling for image generation or processing.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":112-124",
            "content": "                                                    callback=callback,\n                                                    img_callback=img_callback,\n                                                    quantize_denoised=quantize_x0,\n                                                    mask=mask, x0=x0,\n                                                    ddim_use_original_steps=False,\n                                                    noise_dropout=noise_dropout,\n                                                    temperature=temperature,\n                                                    score_corrector=score_corrector,\n                                                    corrector_kwargs=corrector_kwargs,\n                                                    x_T=x_T,\n                                                    log_every_t=log_every_t,\n                                                    unconditional_guidance_scale=unconditional_guidance_scale,\n                                                    unconditional_conditioning=unconditional_conditioning,"
        },
        {
            "comment": "This function performs DDIM sampling using the specified `cond`, `shape` and other optional parameters. It returns the generated samples and intermediates if required. The function is wrapped in a `torch.no_grad()` context to avoid unnecessary gradients computation.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":125-144",
            "content": "                                                    verbose=verbose,\n                                                    precision=precision,\n                                                    fs=fs,\n                                                    **kwargs)\n        return samples, intermediates\n    @torch.no_grad()\n    def ddim_sampling(self, cond, shape,\n                      x_T=None, ddim_use_original_steps=False,\n                      callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, log_every_t=100,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None, verbose=True,precision=None,fs=None,\n                      **kwargs):\n        device = self.model.betas.device        \n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T"
        },
        {
            "comment": "This code block is responsible for handling the timesteps and preparing the inputs for DDIM sampling in a diffusion model. It first checks if precision or timesteps are specified, then determines the appropriate timesteps to use based on ddim_use_original_steps flag. It creates intermediates dictionary, defines time range for iterating through timesteps, and optionally sets up progress bar. Lastly, it processes clean_cond parameter and prepares tensor of current timestep (ts).",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":145-166",
            "content": "        if precision is not None:\n            if precision == 16:\n                img = img.to(dtype=torch.float16)\n        if timesteps is None:\n            timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps\n        elif timesteps is not None and not ddim_use_original_steps:\n            subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1\n            timesteps = self.ddim_timesteps[:subset_end]\n        intermediates = {'x_inter': [img], 'pred_x0': [img]}\n        time_range = reversed(range(0,timesteps)) if ddim_use_original_steps else np.flip(timesteps)\n        total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n        if verbose:\n            iterator = tqdm(time_range, desc='DDIM Sampler', total=total_steps)\n        else:\n            iterator = time_range\n        clean_cond = kwargs.pop(\"clean_cond\", False)\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((b,), step, device=device, dtype=torch.long)"
        },
        {
            "comment": "The code checks if a mask is provided and, if so, blends the noised original latent (img_orig) with the new sampled latent (img) based on the mask value. It also performs a deterministic forward pass using ddim inversion. The function then calls p_sample_ddim to generate the output image.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":168-182",
            "content": "            ## use mask to blend noised original latent (img_orig) & new sampled latent (img)\n            if mask is not None:\n                assert x0 is not None\n                if clean_cond:\n                    img_orig = x0\n                else:\n                    img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass? <ddim inversion>\n                img = img_orig * mask + (1. - mask) * img # keep original & modify use img\n            outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n                                      quantize_denoised=quantize_denoised, temperature=temperature,\n                                      noise_dropout=noise_dropout, score_corrector=score_corrector,\n                                      corrector_kwargs=corrector_kwargs,\n                                      unconditional_guidance_scale=unconditional_guidance_scale,\n                                      unconditional_conditioning=unconditional_conditioning,"
        },
        {
            "comment": "This code is part of the DDIM (Denoising Diffusion Probabilistic Models) sampler in a machine learning model. It takes in inputs, runs a denoising process, and outputs denoised images or video frames. The code allows for various optional parameters to control the sampling process, such as temperature, noise dropout rate, and guidance scale. It also supports conditional guidance and can handle video input if needed.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":183-209",
            "content": "                                      mask=mask,x0=x0,fs=fs,\n                                      **kwargs)\n            img, pred_x0 = outs\n            if callback: callback(i)\n            if img_callback: img_callback(pred_x0, i)\n            if index % log_every_t == 0 or index == total_steps - 1:\n                intermediates['x_inter'].append(img)\n                intermediates['pred_x0'].append(pred_x0)\n        return img, intermediates\n    @torch.no_grad()\n    def p_sample_ddim(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None,\n                      uc_type=None, conditional_guidance_scale_temporal=None,mask=None,x0=None, **kwargs):\n        b, *_, device = *x.shape, x.device\n        if x.dim() == 5:\n            is_video = True\n        else:\n            is_video = False\n        if unconditional_conditioning is None or unconditional_guidance_scale == 1.:"
        },
        {
            "comment": "This code applies the model to generate e_t, considering both conditional and unconditional conditioning. If the conditioning is a tensor or dict, it calculates e_t_cond and e_t_uncond separately, then combines them based on guidance scale. The parameterization type determines if e_t needs further transformation. Alphas values are used for cumulative product calculations depending on the use_original_steps flag.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":210-231",
            "content": "            e_t = self.model.apply_model(x, t, c, **kwargs) # unet denoiser\n        else:\n            ### with unconditional condition\n            if isinstance(c, torch.Tensor) or isinstance(c, dict):\n                e_t_cond = self.model.apply_model(x, t, c, **kwargs)\n                e_t_uncond = self.model.apply_model(x, t, unconditional_conditioning, **kwargs)\n            else:\n                raise NotImplementedError\n            e_t = e_t_uncond + unconditional_guidance_scale * (e_t_cond - e_t_uncond)\n        if self.model.parameterization == \"v\":\n            e_t = self.model.predict_eps_from_z_and_v(x, t, e_t)\n        if score_corrector is not None:\n            assert self.model.parameterization == \"eps\"\n            e_t = score_corrector.modify_score(self.model, e_t, x, t, c, **corrector_kwargs)\n        alphas = self.model.alphas_cumprod if use_original_steps else self.ddim_alphas\n        alphas_prev = self.model.alphas_cumprod_prev if use_original_steps else self.ddim_alphas_prev\n        sqrt_"
        },
        {
            "comment": "This code snippet selects parameters based on the current timestep, calculates the prediction for x0, and applies dynamic rescaling if needed. It handles both video and non-video inputs, and uses different parameterization methods depending on the model setting.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":231-251",
            "content": "one_minus_alphas = self.model.sqrt_one_minus_alphas_cumprod if use_original_steps else self.ddim_sqrt_one_minus_alphas\n        sigmas = self.ddim_sigmas_for_original_num_steps if use_original_steps else self.ddim_sigmas\n        # select parameters corresponding to the currently considered timestep\n        if is_video:\n            size = (b, 1, 1, 1, 1)\n        else:\n            size = (b, 1, 1, 1)\n        a_t = torch.full(size, alphas[index], device=device)\n        a_prev = torch.full(size, alphas_prev[index], device=device)\n        sigma_t = torch.full(size, sigmas[index], device=device)\n        sqrt_one_minus_at = torch.full(size, sqrt_one_minus_alphas[index],device=device)\n        # current prediction for x_0\n        if self.model.parameterization != \"v\":\n            pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n        else:\n            pred_x0 = self.model.predict_start_from_z_and_v(x, t, e_t)\n        if self.model.use_dynamic_rescale:\n            scale_t = torch.full(size, self.ddim_scale_arr[index], device=device)"
        },
        {
            "comment": "This code defines a DDIM decoding function for a diffusion model. It calculates intermediate variables for each time step, denoises the input using a first-stage model, and applies noise dropout if applicable. The decode method takes latent input, conditional information, start timestep, optional guidance scale, unconditional conditioning, use_original_steps flag, and a callback function as arguments to generate intermediate time steps and output the final result.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":252-277",
            "content": "            prev_scale_t = torch.full(size, self.ddim_scale_arr_prev[index], device=device)\n            rescale = (prev_scale_t / scale_t)\n            pred_x0 *= rescale\n        if quantize_denoised:\n            pred_x0, _, *_ = self.model.first_stage_model.quantize(pred_x0)\n        # direction pointing to x_t\n        dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n        noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout > 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        x_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n        return x_prev, pred_x0\n    @torch.no_grad()\n    def decode(self, x_latent, cond, t_start, unconditional_guidance_scale=1.0, unconditional_conditioning=None,\n               use_original_steps=False, callback=None):\n        timesteps = np.arange(self.ddpm_num_timesteps) if use_original_steps else self.ddim_timesteps\n        timesteps = timesteps[:t_start]\n        time_range = np.flip(timesteps)\n        total_steps = timesteps.shape[0]"
        },
        {
            "comment": "This code snippet is performing DDIM (Denoising Diffusion Probabilistic Models) sampling with a specified number of timesteps. It uses the `p_sample_ddim` function to iterate over the steps, applying noisy transitions and denoising them step-by-step. The `stochastic_encode` function provides a fast but non-exact reconstruction method for the latent space.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":278-296",
            "content": "        print(f\"Running DDIM Sampling with {total_steps} timesteps\")\n        iterator = tqdm(time_range, desc='Decoding image', total=total_steps)\n        x_dec = x_latent\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((x_latent.shape[0],), step, device=x_latent.device, dtype=torch.long)\n            x_dec, _ = self.p_sample_ddim(x_dec, cond, ts, index=index, use_original_steps=use_original_steps,\n                                          unconditional_guidance_scale=unconditional_guidance_scale,\n                                          unconditional_conditioning=unconditional_conditioning)\n            if callback: callback(i)\n        return x_dec\n    @torch.no_grad()\n    def stochastic_encode(self, x0, t, use_original_steps=False, noise=None):\n        # fast, but does not allow for exact reconstruction\n        # t serves as an index to gather the correct alphas\n        if use_original_steps:\n            sqrt_alphas_cumprod = self.sqrt_alphas_cumprod"
        },
        {
            "comment": "Computes and returns the denoising diffusion model's (DDPM) sample using provided inputs. If noise is None, generates random noise. Multiplies alpha_cumprod and one_minus_alpha_cumprod with x0 and noise respectively before summing them.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim.py\":297-305",
            "content": "            sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod\n        else:\n            sqrt_alphas_cumprod = torch.sqrt(self.ddim_alphas)\n            sqrt_one_minus_alphas_cumprod = self.ddim_sqrt_one_minus_alphas\n        if noise is None:\n            noise = torch.randn_like(x0)\n        return (extract_into_tensor(sqrt_alphas_cumprod, t, x0.shape) * x0 +\n                extract_into_tensor(sqrt_one_minus_alphas_cumprod, t, x0.shape) * noise)"
        }
    ]
}