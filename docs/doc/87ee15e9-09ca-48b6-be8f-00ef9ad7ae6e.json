{
    "summary": "The DDIMSampler class enables efficient diffusion model sampling using Numpy and GPU buffers, implementing denoising diffusion probabilistic models for image generation with adjustable outputs and a DDIM sampler. The code defines a DDIM multiple condition sampler for stochastic encoding, iterating over timesteps and providing encoded output based on alpha values and optional callbacks.",
    "details": [
        {
            "comment": "This code defines a DDIMSampler class for diffusion model sampling. It takes a model, schedule, and optional keyword arguments as inputs. The class has methods to make a schedule based on the number of desired DDIM steps, discretization method, and eta value. It also includes helper methods like register_buffer for managing buffers in the sampler.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":0-24",
            "content": "import numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom lvdm.models.utils_diffusion import make_ddim_sampling_parameters, make_ddim_timesteps\nfrom lvdm.common import noise_like\nfrom lvdm.common import extract_into_tensor\nclass DDIMSampler(object):\n    def __init__(self, model, schedule=\"linear\", **kwargs):\n        super().__init__()\n        self.model = model\n        self.ddpm_num_timesteps = model.num_timesteps\n        self.schedule = schedule\n        self.counter = 0\n    def register_buffer(self, name, attr):\n        if type(attr) == torch.Tensor:\n            if attr.device != torch.device(\"cuda\"):\n                attr = attr.to(torch.device(\"cuda\"))\n        setattr(self, name, attr)\n    def make_schedule(self, ddim_num_steps, ddim_discretize=\"uniform\", ddim_eta=0., verbose=True):\n        self.ddim_timesteps = make_ddim_timesteps(ddim_discr_method=ddim_discretize, num_ddim_timesteps=ddim_num_steps,\n                                                  num_ddpm_timesteps=self.ddpm_num_timesteps,verbose=verbose)"
        },
        {
            "comment": "This code initializes variables for the DDPM sampler. It checks the shape of alphas_cumprod and registers buffers for betas, alphas_cumprod, alphas_cumprod_prev, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, log_one_minus_alphas_cumprod, sqrt_recip_alphas_cumprod, and sqrt_recipm1_alphas_cumprod. All buffers are created with the same device as the model for efficient GPU usage.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":25-38",
            "content": "        alphas_cumprod = self.model.alphas_cumprod\n        assert alphas_cumprod.shape[0] == self.ddpm_num_timesteps, 'alphas have to be defined for each timestep'\n        to_torch = lambda x: x.clone().detach().to(torch.float32).to(self.model.device)\n        self.register_buffer('betas', to_torch(self.model.betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(self.model.alphas_cumprod_prev))\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod.cpu())))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu())))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod.cpu() - 1)))"
        },
        {
            "comment": "This code segment is initializing DDIM sampling parameters and buffers for the model. It calculates ddim_sigmas, ddim_alphas, ddim_alphas_prev, and other related values to be used in the sample function later. The code also uses numpy for some calculations and registers these buffer parameters to the model for future use.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":40-55",
            "content": "        # ddim sampling parameters\n        ddim_sigmas, ddim_alphas, ddim_alphas_prev = make_ddim_sampling_parameters(alphacums=alphas_cumprod.cpu(),\n                                                                                   ddim_timesteps=self.ddim_timesteps,\n                                                                                   eta=ddim_eta,verbose=verbose)\n        self.register_buffer('ddim_sigmas', ddim_sigmas)\n        self.register_buffer('ddim_alphas', ddim_alphas)\n        self.register_buffer('ddim_alphas_prev', ddim_alphas_prev)\n        self.register_buffer('ddim_sqrt_one_minus_alphas', np.sqrt(1. - ddim_alphas))\n        sigmas_for_original_sampling_steps = ddim_eta * torch.sqrt(\n            (1 - self.alphas_cumprod_prev) / (1 - self.alphas_cumprod) * (\n                        1 - self.alphas_cumprod / self.alphas_cumprod_prev))\n        self.register_buffer('ddim_sigmas_for_original_num_steps', sigmas_for_original_sampling_steps)\n    @torch.no_grad()\n    def sample(self,\n               S,"
        },
        {
            "comment": "This function takes multiple arguments for DDIM sampler including batch_size, shape, conditioning (if any), callbacks, and more. It checks the shape of the conditioning input.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":56-86",
            "content": "               batch_size,\n               shape,\n               conditioning=None,\n               callback=None,\n               normals_sequence=None,\n               img_callback=None,\n               quantize_x0=False,\n               eta=0.,\n               mask=None,\n               x0=None,\n               temperature=1.,\n               noise_dropout=0.,\n               score_corrector=None,\n               corrector_kwargs=None,\n               verbose=True,\n               schedule_verbose=False,\n               x_T=None,\n               log_every_t=100,\n               unconditional_guidance_scale=1.,\n               unconditional_conditioning=None,\n               precision=None,\n               fs=None,\n               # this has to come in the same format as the conditioning, # e.g. as encoded tokens, ...\n               **kwargs\n               ):\n        # check condition bs\n        if conditioning is not None:\n            if isinstance(conditioning, dict):\n                try:\n                    cbs = conditioning[list(conditioning.keys())[0]].shape[0]"
        },
        {
            "comment": "This code block checks if the number of conditionings matches the batch size, and if not, it prints a warning. It then determines the shape of the samples based on the input shape and creates a data structure for DDIM sampling with the specified eta value.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":87-109",
            "content": "                except:\n                    cbs = conditioning[list(conditioning.keys())[0]][0].shape[0]\n                if cbs != batch_size:\n                    print(f\"Warning: Got {cbs} conditionings but batch-size is {batch_size}\")\n            else:\n                if conditioning.shape[0] != batch_size:\n                    print(f\"Warning: Got {conditioning.shape[0]} conditionings but batch-size is {batch_size}\")\n        self.make_schedule(ddim_num_steps=S, ddim_eta=eta, verbose=schedule_verbose)\n        # make shape\n        if len(shape) == 3:\n            C, H, W = shape\n            size = (batch_size, C, H, W)\n        elif len(shape) == 4:\n            C, T, H, W = shape\n            size = (batch_size, C, T, H, W)\n        # print(f'Data shape for DDIM sampling is {size}, eta {eta}')\n        samples, intermediates = self.ddim_sampling(conditioning, size,\n                                                    callback=callback,\n                                                    img_callback=img_callback,"
        },
        {
            "comment": "This code is calling the DDIM sampler function with multiple conditions. The function takes inputs like quantized denoised sample, mask, original noise image, temperature, score corrector, corrector kwargs, final output x_T, logging frequency, unconditional guidance scale, unconditional conditioning, verbose mode, and precision for the computation.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":110-122",
            "content": "                                                    quantize_denoised=quantize_x0,\n                                                    mask=mask, x0=x0,\n                                                    ddim_use_original_steps=False,\n                                                    noise_dropout=noise_dropout,\n                                                    temperature=temperature,\n                                                    score_corrector=score_corrector,\n                                                    corrector_kwargs=corrector_kwargs,\n                                                    x_T=x_T,\n                                                    log_every_t=log_every_t,\n                                                    unconditional_guidance_scale=unconditional_guidance_scale,\n                                                    unconditional_conditioning=unconditional_conditioning,\n                                                    verbose=verbose,\n                                                    precision=precision,"
        },
        {
            "comment": "The provided code is the definition of a function called \"ddim_sampling\" for creating samples using the DDIM (Denoising Diffusion Probabilistic Models) algorithm. This function takes conditional input, shape, and other optional arguments to generate denoised images. It also has parameters for precision, timesteps, and temperature control.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":123-146",
            "content": "                                                    fs=fs,\n                                                    **kwargs)\n        return samples, intermediates\n    @torch.no_grad()\n    def ddim_sampling(self, cond, shape,\n                      x_T=None, ddim_use_original_steps=False,\n                      callback=None, timesteps=None, quantize_denoised=False,\n                      mask=None, x0=None, img_callback=None, log_every_t=100,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None, verbose=True,precision=None,fs=None,\n                      **kwargs):\n        device = self.model.betas.device        \n        b = shape[0]\n        if x_T is None:\n            img = torch.randn(shape, device=device)\n        else:\n            img = x_T\n        if precision is not None:\n            if precision == 16:\n                img = img.to(dtype=torch.float16)\n        if timesteps is None:"
        },
        {
            "comment": "The code determines the timesteps for the DDIM sampler, and initializes intermediates and time_range variables. It then creates a progress bar (if verbose) or an iterator for the specified number of timesteps. Finally, it prepares a tensor with step values and uses it to blend noised original latent and new sampled latents.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":147-165",
            "content": "            timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps\n        elif timesteps is not None and not ddim_use_original_steps:\n            subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1\n            timesteps = self.ddim_timesteps[:subset_end]\n        intermediates = {'x_inter': [img], 'pred_x0': [img]}\n        time_range = reversed(range(0,timesteps)) if ddim_use_original_steps else np.flip(timesteps)\n        total_steps = timesteps if ddim_use_original_steps else timesteps.shape[0]\n        if verbose:\n            iterator = tqdm(time_range, desc='DDIM Sampler', total=total_steps)\n        else:\n            iterator = time_range\n        clean_cond = kwargs.pop(\"clean_cond\", False)\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((b,), step, device=device, dtype=torch.long)\n            ## use mask to blend noised original latent (img_orig) & new sampled latent (img)"
        },
        {
            "comment": "The code checks if mask is not None and asserts that x0 is not also None. If clean_cond is True, it assigns the original image (x0) to img_orig. Otherwise, it runs a deterministic forward pass on model using q_sample method for x0 and ts. Then it calculates the final image (img) by combining img_orig and existing img with mask values. Finally, it calls p_sample_ddim method with calculated inputs and stores the results in outs variable.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":166-181",
            "content": "            if mask is not None:\n                assert x0 is not None\n                if clean_cond:\n                    img_orig = x0\n                else:\n                    img_orig = self.model.q_sample(x0, ts)  # TODO: deterministic forward pass? <ddim inversion>\n                img = img_orig * mask + (1. - mask) * img # keep original & modify use img\n            outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,\n                                      quantize_denoised=quantize_denoised, temperature=temperature,\n                                      noise_dropout=noise_dropout, score_corrector=score_corrector,\n                                      corrector_kwargs=corrector_kwargs,\n                                      unconditional_guidance_scale=unconditional_guidance_scale,\n                                      unconditional_conditioning=unconditional_conditioning,\n                                      mask=mask,x0=x0,fs=fs,\n                                      **kwargs)"
        },
        {
            "comment": "This code defines a p_sample_ddim function that performs denoising diffusion probabilistic models for generating images. It takes input x, c, t, index, and various other parameters, returns the generated image and intermediates. The function checks if the index is appropriate for logging intermediates and appends to intermediates list 'x_inter' and 'pred_x0'. If cfg_img is None, it sets cfg_img as unconditional_guidance_scale. This function also determines if the input x is of dimension 5 indicating a video.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":185-208",
            "content": "            img, pred_x0 = outs\n            if callback: callback(i)\n            if img_callback: img_callback(pred_x0, i)\n            if index % log_every_t == 0 or index == total_steps - 1:\n                intermediates['x_inter'].append(img)\n                intermediates['pred_x0'].append(pred_x0)\n        return img, intermediates\n    @torch.no_grad()\n    def p_sample_ddim(self, x, c, t, index, repeat_noise=False, use_original_steps=False, quantize_denoised=False,\n                      temperature=1., noise_dropout=0., score_corrector=None, corrector_kwargs=None,\n                      unconditional_guidance_scale=1., unconditional_conditioning=None,\n                      uc_type=None, cfg_img=None,mask=None,x0=None, **kwargs):\n        b, *_, device = *x.shape, x.device\n        if x.dim() == 5:\n            is_video = True\n        else:\n            is_video = False\n        if cfg_img is None:\n            cfg_img = unconditional_guidance_scale\n        unconditional_conditioning_img_nonetext = kwargs['unconditional_conditioning_img_nonetext']"
        },
        {
            "comment": "This code applies the model to generate an output based on conditional and unconditional inputs, with possible modification of scores using a score corrector. It also adjusts the output based on the model's parameterization setting.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":211-229",
            "content": "        if unconditional_conditioning is None or unconditional_guidance_scale == 1.:\n            e_t = self.model.apply_model(x, t, c, **kwargs) # unet denoiser\n        else:\n            ### with unconditional condition\n            e_t_cond = self.model.apply_model(x, t, c, **kwargs)\n            e_t_uncond = self.model.apply_model(x, t, unconditional_conditioning, **kwargs)\n            e_t_uncond_img = self.model.apply_model(x, t, unconditional_conditioning_img_nonetext, **kwargs)\n            # text cfg\n            e_t = e_t_uncond + cfg_img * (e_t_uncond_img - e_t_uncond) + unconditional_guidance_scale * (e_t_cond - e_t_uncond_img)\n        if self.model.parameterization == \"v\":\n            e_t = self.model.predict_eps_from_z_and_v(x, t, e_t)\n        if score_corrector is not None:\n            assert self.model.parameterization == \"eps\"\n            e_t = score_corrector.modify_score(self.model, e_t, x, t, c, **corrector_kwargs)\n        alphas = self.model.alphas_cumprod if use_original_steps else self.ddim_alphas"
        },
        {
            "comment": "This code is assigning variables for DDIM sampler's timestep-specific parameters and creating a prediction for the initial frame x0. It first selects alphas, alpha_prev, sqrt_one_minus_alphas, and sigmas based on use_original_steps and considers the current index. For video input, it creates a size of (b, 1, 1, 1, 1) while for other inputs, it uses (b, 1, 1, 1). It then initializes variables a_t, a_prev, sigma_t, and sqrt_one_minus_at with the respective indices. After that, it computes pred_x0 using the formula (x - sqrt_one_minus_at * e_t) / a_t.sqrt(). Finally, if quantize_denoised is True, it quantizes the prediction using first_stage_model's quantize method.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":230-249",
            "content": "        alphas_prev = self.model.alphas_cumprod_prev if use_original_steps else self.ddim_alphas_prev\n        sqrt_one_minus_alphas = self.model.sqrt_one_minus_alphas_cumprod if use_original_steps else self.ddim_sqrt_one_minus_alphas\n        sigmas = self.ddim_sigmas_for_original_num_steps if use_original_steps else self.ddim_sigmas\n        # select parameters corresponding to the currently considered timestep\n        if is_video:\n            size = (b, 1, 1, 1, 1)\n        else:\n            size = (b, 1, 1, 1)\n        a_t = torch.full(size, alphas[index], device=device)\n        a_prev = torch.full(size, alphas_prev[index], device=device)\n        sigma_t = torch.full(size, sigmas[index], device=device)\n        sqrt_one_minus_at = torch.full(size, sqrt_one_minus_alphas[index],device=device)\n        # current prediction for x_0\n        pred_x0 = (x - sqrt_one_minus_at * e_t) / a_t.sqrt()\n        if quantize_denoised:\n            pred_x0, _, *_ = self.model.first_stage_model.quantize(pred_x0)\n        # direction pointing to x_t"
        },
        {
            "comment": "This code is a part of the DDIM multiple condition sampler function in DynamiCrafter/lvdm/models/samplers/ddim_multiplecond.py. It initializes variables and iterates over timesteps, decoding input latent vector x_latent at each time step using DDIM sampling method. The code also includes a progress bar for the decoding process.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":250-275",
            "content": "        dir_xt = (1. - a_prev - sigma_t**2).sqrt() * e_t\n        noise = sigma_t * noise_like(x.shape, device, repeat_noise) * temperature\n        if noise_dropout > 0.:\n            noise = torch.nn.functional.dropout(noise, p=noise_dropout)\n        x_prev = a_prev.sqrt() * pred_x0 + dir_xt + noise\n        return x_prev, pred_x0\n    @torch.no_grad()\n    def decode(self, x_latent, cond, t_start, unconditional_guidance_scale=1.0, unconditional_conditioning=None,\n               use_original_steps=False, callback=None):\n        timesteps = np.arange(self.ddpm_num_timesteps) if use_original_steps else self.ddim_timesteps\n        timesteps = timesteps[:t_start]\n        time_range = np.flip(timesteps)\n        total_steps = timesteps.shape[0]\n        print(f\"Running DDIM Sampling with {total_steps} timesteps\")\n        iterator = tqdm(time_range, desc='Decoding image', total=total_steps)\n        x_dec = x_latent\n        for i, step in enumerate(iterator):\n            index = total_steps - i - 1\n            ts = torch.full((x_latent.shape[0],), step, device=x_latent.device, dtype=torch.long)"
        },
        {
            "comment": "This code defines a function that performs stochastic encoding using the DDIM sampler with multiple conditions. The function uses the provided `x0`, `t`, and optional `noise` inputs to generate the encoded output. It checks if `use_original_steps` is True, and if so, uses precomputed `sqrt_alphas_cumprod` and `sqrt_one_minus_alphas_cumprod`. Otherwise, it computes `sqrt_alphas_cumprod` based on the DDIM alpha values. It then applies a noise term to generate the encoded output by multiplying the extracted `sqrt_alphas_cumprod` with `x0` and adding them together. The function also provides an optional callback that can be used to monitor progress during the encoding process.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":276-295",
            "content": "            x_dec, _ = self.p_sample_ddim(x_dec, cond, ts, index=index, use_original_steps=use_original_steps,\n                                          unconditional_guidance_scale=unconditional_guidance_scale,\n                                          unconditional_conditioning=unconditional_conditioning)\n            if callback: callback(i)\n        return x_dec\n    @torch.no_grad()\n    def stochastic_encode(self, x0, t, use_original_steps=False, noise=None):\n        # fast, but does not allow for exact reconstruction\n        # t serves as an index to gather the correct alphas\n        if use_original_steps:\n            sqrt_alphas_cumprod = self.sqrt_alphas_cumprod\n            sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod\n        else:\n            sqrt_alphas_cumprod = torch.sqrt(self.ddim_alphas)\n            sqrt_one_minus_alphas_cumprod = self.ddim_sqrt_one_minus_alphas\n        if noise is None:\n            noise = torch.randn_like(x0)\n        return (extract_into_tensor(sqrt_alphas_cumprod, t, x0.shape) * x0 +"
        },
        {
            "comment": "This code block is multiplying the square root of one minus alphas' cumulative product by the noise and assigning it to x0. This operation helps in generating samples from a diffusion model.",
            "location": "\"/media/root/Prima/works/DynamiCrafter/docs/src/lvdm/models/samplers/ddim_multiplecond.py\":296-296",
            "content": "                extract_into_tensor(sqrt_one_minus_alphas_cumprod, t, x0.shape) * noise)"
        }
    ]
}