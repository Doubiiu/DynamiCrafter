{"_default": {"1": {"path": "/README.md", "hash": "d2e71f0fe265f8d030a78facb2e40e5f", "title": "Generate Videos from Tables with DynamiCrafter"}, "2": {"path": "/README.md:1-15", "hash": "189f9dce90981bfc520379f8d956ead4", "title": "Open-Domain Image Animation Tool"}, "3": {"path": "/README.md:15-29", "hash": "988d0b2c71f90d7101ddaf46b9418176", "title": "DynamiCrafter: Demo and Cloud API Access"}, "4": {"path": "/README.md:30-75", "hash": "4be0bd447dc5cd7d73e28e027fcc177d", "title": "Dynamic Showcase Tables for DynamiCrafter"}, "5": {"path": "/README.md:76-100", "hash": "9a98ce5a9561f9d44926a351f2d9ec07", "title": "Springtime Landscape and Surreal Vignettes"}, "6": {"path": "/README.md:101-147", "hash": "1c975ceb596b8496baa99412c457ad0b", "title": "Dynamic Media Display in Table Format"}, "7": {"path": "/README.md:148-194", "hash": "6092a1f7aa08e3eba1762c3412b885f1", "title": "Video Table Code Example"}, "8": {"path": "/README.md:195-231", "hash": "a0eb3aacb8bb80d91aad64e730734e4e", "title": "DynamiCrafter Setup and Usage Guide"}, "9": {"path": "/README.md:232-259", "hash": "9425dc291f9ab4f3aee62295aef1c77c", "title": "DynamiCrafter Setup and Demo Guide"}, "10": {"path": "/README.md:261-277", "hash": "67a487acf91ee14173fe05dd62d16bb0", "title": "DynamicCrafter Toolkit: Text-to-Image, Text-to-Video"}, "11": {"path": "/configs/inference_256_v1.0.yaml", "hash": "23ea5a55b1dc7d919e4e30f4cf1746ba", "title": "Deep Learning Image Config"}, "12": {"path": "/configs/inference_256_v1.0.yaml:1-44", "hash": "8f4b0425b956ccbb9d95f154f1c0dff4", "title": "Deep Learning Image Generator Config"}, "13": {"path": "/configs/inference_256_v1.0.yaml:45-87", "hash": "1b9070fd2b599ac90887d33b4fa6ee3b", "title": "Autoencoder-based Image Inpainting Configuration"}, "14": {"path": "/configs/inference_256_v1.0.yaml:88-97", "hash": "aa7e91c66e7ea863b6443de8134a0bbf", "title": "YAML Neural Model Inference Parameters"}, "15": {"path": "/gradio_app.py", "hash": "3eb56889474da426e50432dfa369f5f7", "title": "Gradio Video Demo Generator"}, "16": {"path": "/gradio_app.py:1-22", "hash": "f1aec980d7420388aa6cc1b769089c19", "title": "Dynamic Video Generation with Gradio"}, "17": {"path": "/gradio_app.py:23-32", "hash": "d5a88edd25539ec4b0cab26d053b0d79", "title": "Author & GitHub Links - DynamiCrafter Project"}, "18": {"path": "/gradio_app.py:33-48", "hash": "ba5dfd3a5d85e9e8799133b26fb86a53", "title": "Image2Video Tab Creation in Gradio"}, "19": {"path": "/gradio_app.py:49-62", "hash": "d52807e80a61148c29c9932974e051ca", "title": "Interactive UI for Motion Magnitude and Steps"}, "20": {"path": "/gradio_app.py:63-74", "hash": "f2de7f135be2f791faa0ba621d7632c6", "title": "Launching DynamicRafter Tasks"}, "21": {"path": "/lvdm/basics.py", "hash": "505fa3f0e441c7ca2d207e99fedc58fe", "title": "Convolutional Layers in Deep Learning Models"}, "22": {"path": "/lvdm/basics.py:1-36", "hash": "b7ad92d70ddf914bededbfc0e902cc0e", "title": "Convolutional Layer Module Functions"}, "23": {"path": "/lvdm/basics.py:37-81", "hash": "a2b8205c35712d02eab691f89d517f2a", "title": "Deep Learning Module Utilities"}, "24": {"path": "/lvdm/basics.py:82-100", "hash": "b997195a0d83b74eeb9937c3fbf045ac", "title": "Normalization Layer with Hybrid Conditioner"}, "25": {"path": "/lvdm/common.py", "hash": "13bcb1c52735764dd606ce812379fefc", "title": "Utility Functions for Efficient Data Processing"}, "26": {"path": "/lvdm/common.py:1-32", "hash": "df52448788893dc2985dd79285f9b77a", "title": "Multi-Process Data Gathering and Mixed Precision Utilities"}, "27": {"path": "/lvdm/common.py:33-77", "hash": "85b1b322b4bd5219b9333dc053664b89", "title": "Utility Functions Collection"}, "28": {"path": "/lvdm/common.py:78-94", "hash": "5ff9d08d1df9524fab37d1624303da18", "title": "Checkpointing Evaluation Function"}, "29": {"path": "/lvdm/distributions.py", "hash": "988ce19cf0f466639f537ec0761e8770", "title": "AbstractDistribution Class and KL Divergence Computation"}, "30": {"path": "/lvdm/distributions.py:1-39", "hash": "258e4f2b03731a50c31bd729dd82b053", "title": "Learnable Distributions: Dirac and Diagonal Gaussian"}, "31": {"path": "/lvdm/distributions.py:40-70", "hash": "8a2d4d8ba227c2b2e48476b71f8820e7", "title": "Gaussian Divergence and Normalization Tool"}, "32": {"path": "/lvdm/distributions.py:71-95", "hash": "50c8e8a429901e3c7cc4937325119b5d", "title": "KL Divergence of Gaussian Distributions"}, "33": {"path": "/lvdm/ema.py", "hash": "194d137a9ffac593b7da43418356f42d", "title": "LitEMA: Efficient EMA in PyTorch"}, "34": {"path": "/lvdm/ema.py:1-30", "hash": "c62fbdfd1453ba8cd04cb9ef47e9130f", "title": "Exponential Moving Average (EMA) in PyTorch"}, "35": {"path": "/lvdm/ema.py:32-57", "hash": "2128834ea6520813f4638ca342cfe29d", "title": "Shadow Parameter Management Class"}, "36": {"path": "/lvdm/ema.py:58-76", "hash": "953050142e527422f5a0c529c3e34573", "title": "EMA Temporary Parameters Storage"}, "37": {"path": "/lvdm/models/autoencoder.py", "hash": "cfa32b8d6b73cf5db3bea4973bf814e0", "title": "Autoencoder Model with Colorization"}, "38": {"path": "/lvdm/models/autoencoder.py:1-33", "hash": "c3b0683d93b48f3a67008e3cfececcf0", "title": "AutoencoderKL: LVDM Framework Model"}, "39": {"path": "/lvdm/models/autoencoder.py:34-56", "hash": "35c2500c78222e064c732ea23049d083", "title": "Autoencoder Model Initialization"}, "40": {"path": "/lvdm/models/autoencoder.py:57-82", "hash": "0d8e3ae294235d0321632655afb80bd7", "title": "Autoencoder Save Directory Setup and Checkpoint Loading"}, "41": {"path": "/lvdm/models/autoencoder.py:83-116", "hash": "8cd47541d577d7b415704844820b6e36", "title": "Autoencoder Model: Encoder-Decoder Class"}, "42": {"path": "/lvdm/models/autoencoder.py:118-142", "hash": "e9bb785e255ce88ae16a5d34eefc6723", "title": "Autoencoder Model: Get Input and Training Step"}, "43": {"path": "/lvdm/models/autoencoder.py:143-161", "hash": "32d2984d49fd467c7beb89468637ca3f", "title": "Training and Validation Losses"}, "44": {"path": "/lvdm/models/autoencoder.py:163-186", "hash": "cd83f88cca57ca9d8427d931d81af6d9", "title": "Configure Optimizers and Log Images"}, "45": {"path": "/lvdm/models/autoencoder.py:187-215", "hash": "f672d1e235ac02102988ad3bf225213c", "title": "Identity-Aware Autoencoder with Colorization"}, "46": {"path": "/lvdm/models/autoencoder.py:216-219", "hash": "54dc150303d57c46cc624d9c2d3fed0c", "title": "Placeholder Functions"}, "47": {"path": "/lvdm/models/ddpm3d.py", "hash": "0a39855d6e85b05cee187ed881cf93b9", "title": "Conditional 3D DDPM Image Generation"}, "48": {"path": "/lvdm/models/ddpm3d.py:1-32", "hash": "7cefcd873f8de0b7a20ee4b8fe0a5167", "title": "DDPM3D Module Code"}, "49": {"path": "/lvdm/models/ddpm3d.py:33-60", "hash": "1a2e72966baf68e8fec09f542b86853b", "title": "DDPM Gaussian Image Class Definition"}, "50": {"path": "/lvdm/models/ddpm3d.py:61-80", "hash": "24327e1bb8d4cd5299856a46f4d8878b", "title": "DDPM Model Initialization"}, "51": {"path": "/lvdm/models/ddpm3d.py:81-104", "hash": "016aae26494eb8c1a69a0d034199874d", "title": "DDPM3D Model Initialization"}, "52": {"path": "/lvdm/models/ddpm3d.py:106-126", "hash": "fbe1e25c2c1f50fc8f0d17bb163d3ff3", "title": "DDPM Model Initialization and Scheduling"}, "53": {"path": "/lvdm/models/ddpm3d.py:128-143", "hash": "d9217da1ab8fde1cdbc4440d16458f78", "title": "Diffusion Model Initialization and Calculation"}, "54": {"path": "/lvdm/models/ddpm3d.py:144-157", "hash": "b135c7b6d54c258014460afc3c4a2cf7", "title": "Defining Buffers and Weights in DDPM3D Model"}, "55": {"path": "/lvdm/models/ddpm3d.py:158-181", "hash": "8770998f57bd1f07b63ca95bbda70a7c", "title": "EMA-based Model Parameterization"}, "56": {"path": "/lvdm/models/ddpm3d.py:183-204", "hash": "f939d453c0d386a991108dbe91af0ad9", "title": "Loading and Computing Distribution for 3D DDPM Models"}, "57": {"path": "/lvdm/models/ddpm3d.py:205-222", "hash": "333cf1bbf5d7479fcf3b7874f5081b9c", "title": "DDPM3D Predict Start Values"}, "58": {"path": "/lvdm/models/ddpm3d.py:223-242", "hash": "d688d5dd852cebd35484bd28286726b9", "title": "DDPM3D Model Methods"}, "59": {"path": "/lvdm/models/ddpm3d.py:243-264", "hash": "32cd0f9fe56db2e4cfa8f3e0a45eaf9a", "title": "DDPM 3D Model Sampling"}, "60": {"path": "/lvdm/models/ddpm3d.py:265-286", "hash": "eb1b4b8db9ac7e7a4905643b7a7b63e8", "title": "Reversible Diffusion Model for 3D Image Sampling"}, "61": {"path": "/lvdm/models/ddpm3d.py:287-311", "hash": "f2bcbffb6347d818ae2aaaf7edff2aaf", "title": "Image Processing Methods"}, "62": {"path": "/lvdm/models/ddpm3d.py:312-340", "hash": "67bc60cf228243a4a924f2d7af23c452", "title": "Denoising Diffusion Probabilistic Modeling"}, "63": {"path": "/lvdm/models/ddpm3d.py:341-371", "hash": "0e3669fee95deb0287f9afaf7b71d232", "title": "Latent Diffusion Model Training and Saving"}, "64": {"path": "/lvdm/models/ddpm3d.py:372-394", "hash": "f761a7a6ba5dd52424a5ec7777400423", "title": "DDPM3D Model Initialization"}, "65": {"path": "/lvdm/models/ddpm3d.py:395-419", "hash": "bcb26993153b80d8481b9d5dacfea6a3", "title": "Initialize and Verify Model Parameters"}, "66": {"path": "/lvdm/models/ddpm3d.py:420-440", "hash": "1d0a19502004e35386c37197df649198", "title": "Conditional Diffusion Model Initialization"}, "67": {"path": "/lvdm/models/ddpm3d.py:442-462", "hash": "6e36964a0f9501916aa736ae6341fa25", "title": "Model Encoding Methods"}, "68": {"path": "/lvdm/models/ddpm3d.py:464-495", "hash": "5e5a13a6bc5936ab27a52beff10f7776", "title": "Reshaping Encoder and Decoder Functions"}, "69": {"path": "/lvdm/models/ddpm3d.py:497-524", "hash": "28d329aaf378930f943edc8906479d3a", "title": "DDPM 3D Model Reconstruction"}, "70": {"path": "/lvdm/models/ddpm3d.py:525-546", "hash": "f8a99d701d2bc3baceab5cb1053431f2", "title": "Denoise and Reshape Samples Function"}, "71": {"path": "/lvdm/models/ddpm3d.py:547-576", "hash": "7fb50f91f1f0bbcc6aca8b9a91581d9c", "title": "DDPM Data Mean and Variance Calculator"}, "72": {"path": "/lvdm/models/ddpm3d.py:578-596", "hash": "a06ca669651accbe9acd54bf733fd9f9", "title": "Denoising Diffusion Probabilistic Models (DDPM) Sample Function"}, "73": {"path": "/lvdm/models/ddpm3d.py:597-624", "hash": "ded6d20dc1c9e2ed9bce596abc3af546", "title": "Iterative Noise Sampling for DDPM3D Images"}, "74": {"path": "/lvdm/models/ddpm3d.py:626-650", "hash": "25b29790d487cd8d8d49518899ccc308", "title": "Latent Visual Diffusion Model: Image Generation and Denoising"}, "75": {"path": "/lvdm/models/ddpm3d.py:651-674", "hash": "35c9ba8cc26ebed6f13cca375925a073", "title": "Diffusion Wrapper for 3D Models"}, "76": {"path": "/lvdm/models/ddpm3d.py:675-695", "hash": "9050fe051824b0b444e9320612d6927b", "title": "Conditional Diffusion Model Processing"}, "77": {"path": "/lvdm/models/ddpm3d.py:696-718", "hash": "73ee824672f705b401e3c37b91315b7a", "title": "Diffusion Model Conditioning: DDPM3D"}, "78": {"path": "/lvdm/models/ddpm3d.py:719-732", "hash": "6641927585d5c07ef57275eba97f30b7", "title": "Dynamic Key Handling for Diffusion Models"}, "79": {"path": "/lvdm/models/samplers/ddim.py", "hash": "7c1102dda6bcb727180eb9ddc5dce45b", "title": "DDPMSampler: DDPM & DDIM Impl. for Image Gen"}, "80": {"path": "/lvdm/models/samplers/ddim.py:1-25", "hash": "53af01f8e54deac75adc595128ac76d7", "title": "DDIM Sampler: Model, Schedule, and Buffers"}, "81": {"path": "/lvdm/models/samplers/ddim.py:26-41", "hash": "02197784edf2880aa481c9a6be6d9150", "title": "Buffer Initialization for Diffusion Model"}, "82": {"path": "/lvdm/models/samplers/ddim.py:42-55", "hash": "ecab5a00d730e657fb844116afc82ee4", "title": "DDIM Sampling Code in PyTorch"}, "83": {"path": "/lvdm/models/samplers/ddim.py:56-87", "hash": "2149843f034e5eabf5536dfd57cb4e27", "title": "DDPM Sampler Class and Sample Method"}, "84": {"path": "/lvdm/models/samplers/ddim.py:88-112", "hash": "e6ca9a148905b52e3d1e9fd7dd29f798", "title": "DDIM Sampling Setup"}, "85": {"path": "/lvdm/models/samplers/ddim.py:113-125", "hash": "6275b2b159041cbf30f772f2d9395428", "title": "DDPM Image Sampler"}, "86": {"path": "/lvdm/models/samplers/ddim.py:126-145", "hash": "6a4ba8aaeb2e97f0d58f0d86d03fa14c", "title": "DDM Sampling: Generating Samples with Conditions"}, "87": {"path": "/lvdm/models/samplers/ddim.py:146-167", "hash": "b6be952debe5c748617155343ede729a", "title": "DDim Sampler Timestep Handler"}, "88": {"path": "/lvdm/models/samplers/ddim.py:169-183", "hash": "94e4e12278dae1be61e815cf7b58b2a1", "title": "Blend and DDIM Sampling"}, "89": {"path": "/lvdm/models/samplers/ddim.py:184-210", "hash": "c6b16c72be5aecf751d8397f86b50900", "title": "Denoising Diffusion Sampler: DDIM Algorithm"}, "90": {"path": "/lvdm/models/samplers/ddim.py:211-232", "hash": "2bf5acf892ea2ea3d6bda3446b30c4d3", "title": "DDim Model Sampler Calculations"}, "91": {"path": "/lvdm/models/samplers/ddim.py:232-252", "hash": "ed1e452e1a061b384fff7667a2c021f4", "title": "Dynamic Rescaling for DDIM Sampling"}, "92": {"path": "/lvdm/models/samplers/ddim.py:253-278", "hash": "5ae5d63111e9c24eff1d61d06b83011b", "title": "DDim Decoding Function"}, "93": {"path": "/lvdm/models/samplers/ddim.py:279-297", "hash": "34985618e8773edc1f2d64c766fb4163", "title": "Denoising Diffusion Sampling in 279-297 Lines"}, "94": {"path": "/lvdm/models/samplers/ddim.py:298-306", "hash": "d9deec6550559ba321c3dfa462631a5d", "title": "DDPM Sample Generation"}, "95": {"path": "/lvdm/models/samplers/ddim_multiplecond.py", "hash": "d1dd410a50edd12481716e8977144583", "title": "DDIM Multiple Condition Sampler"}, "96": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:1-25", "hash": "eca5e78c346fc44ffdbdb0b824fcb4c3", "title": "DDIMSampler: Diffusion Model Sampling Class"}, "97": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:26-39", "hash": "0d2889556c31b04758201e0131220b43", "title": "DDPM Sampler Variable Initialization"}, "98": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:41-56", "hash": "2cfba8ba4229777d14b1736a8ac43d1c", "title": "DDM Sampling Parameter Initialization"}, "99": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:57-87", "hash": "3a3d247af85f999ca1f084621bb224c1", "title": "DDIM Sampler for Multiple Conditional Inputs"}, "100": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:88-110", "hash": "4f5bb0410a5e401c6a8ea0afb68ab3ce", "title": "DDim Multiple Cond Sampling"}, "101": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:111-123", "hash": "d294df4cc61d1daf946d3d7a4ac8322c", "title": "DDIM Sampler with Multiple Conditions"}, "102": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:124-147", "hash": "355088c5d26cda2c80996451bbb4612d", "title": "Denoising Diffusion Sampling Function"}, "103": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:148-166", "hash": "e9bc119694c9c56eb05a998692763c2f", "title": "DDM Sampler Timestep Initialization"}, "104": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:167-182", "hash": "a9a0045ede62a8127f34bbd7c7a6123b", "title": "DDimMultipleCond Sampler"}, "105": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:186-209", "hash": "6a012e140bf32c97cf35d0315cd08455", "title": "DDim Multiple Conditional Sampler Function"}, "106": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:212-230", "hash": "11cc7cfe0b5ecb588c33207ed1657b54", "title": "DDim Multiple Conditional Sampler"}, "107": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:231-250", "hash": "096277874fd7d5d7e040064076adbe9f", "title": "DDM Sampler Initialization"}, "108": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:251-276", "hash": "bdc774b5319a316c62ba72fc3f8feb13", "title": "DDIM Multiple Condition Sampler: Decoding Progress"}, "109": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:277-296", "hash": "9c3908f4faa7aad1a92119075fe95ea3", "title": "Stochastic Encoding with DDIM Sampler"}, "110": {"path": "/lvdm/models/samplers/ddim_multiplecond.py:297-297", "hash": "12c4bbb97cdcdc98dec05b30b50dc031", "title": "DDM Multiple Cond Sampler"}, "111": {"path": "/lvdm/models/utils_diffusion.py", "hash": "08ee594d35d96c4bafa91b60f6d835ce", "title": "Efficient Deep Learning Diffusion Models"}, "112": {"path": "/lvdm/models/utils_diffusion.py:1-27", "hash": "f659b1c71911cf47cd52abd307047285", "title": "Timestep Embeddings for Diffusion Models"}, "113": {"path": "/lvdm/models/utils_diffusion.py:28-56", "hash": "5c5090713e2d82b4fc98925eec253728", "title": "Diffusion Model Schedule Generator"}, "114": {"path": "/lvdm/models/utils_diffusion.py:57-77", "hash": "99eda66e9e7b4a60f49b9198025ad4f8", "title": "Timestep Generation for DDIM Sampling"}, "115": {"path": "/lvdm/models/utils_diffusion.py:79-96", "hash": "5c2fdcc00339d0cb2c3aec66ecebb353", "title": "Sigma Calculator for DDIM Sampler"}, "116": {"path": "/lvdm/models/utils_diffusion.py:97-104", "hash": "626f781e94dd29c49c030faf908324b7", "title": "Beta Values Generator"}, "117": {"path": "/lvdm/modules/attention.py", "hash": "e9e772fb15ba519233a74d2f19322344", "title": "Efficient Multi-Head Attention for Transformers"}, "118": {"path": "/lvdm/modules/attention.py:1-33", "hash": "ee4929400a6327c1957a3612415e1c85", "title": "Relative Position Embedding Module"}, "119": {"path": "/lvdm/modules/attention.py:34-54", "hash": "bf274629379cd3f493086592e9f1fd4c", "title": "CrossAttention: Cross-Modal Attention Mechanism"}, "120": {"path": "/lvdm/modules/attention.py:55-73", "hash": "0f7617283cb285f13ebb9524fe0a8c6b", "title": "Efficient Spatial-Temporal Attention Module"}, "121": {"path": "/lvdm/modules/attention.py:74-98", "hash": "bee092672ebc5edccd0d81261a62df14", "title": "Cross-Attention Module for Images and Text"}, "122": {"path": "/lvdm/modules/attention.py:99-123", "hash": "f58d71c5355bd8c52512b52142b3779c", "title": "Multi-Head Self-Attention with Relative Position"}, "123": {"path": "/lvdm/modules/attention.py:124-150", "hash": "8ad14a4b022e8765544b7e07e0216390", "title": "Multi-Head Attention with Image Cross-Attention"}, "124": {"path": "/lvdm/modules/attention.py:151-175", "hash": "88f26f38764c4396176a3ef6467a38f8", "title": "Memory-Efficient XFormers Attention"}, "125": {"path": "/lvdm/modules/attention.py:177-203", "hash": "a4a28a09942f683229e808c2c6e34451", "title": "Multi-Head Attention for Image Models"}, "126": {"path": "/lvdm/modules/attention.py:204-221", "hash": "a9bac3b5940436af1e15b36fc9c527a9", "title": "BasicTransformerBlock: Attention and FeedForward Initialization"}, "127": {"path": "/lvdm/modules/attention.py:222-237", "hash": "a220ecf0ff522b0b6a67574959b7a767", "title": "Attention Module Forward Pass"}, "128": {"path": "/lvdm/modules/attention.py:238-261", "hash": "ddd8f96bba6f5918b775d056ece40896", "title": "Spatial Transformer Block"}, "129": {"path": "/lvdm/modules/attention.py:262-285", "hash": "a1a549258f8a40f3a336d9de03ad8abf", "title": "Initialize Attention Module Code"}, "130": {"path": "/lvdm/modules/attention.py:286-316", "hash": "87723ad6cc6c0056480c69de440fc1b9", "title": "Attention-Based Transformer Block for Images"}, "131": {"path": "/lvdm/modules/attention.py:317-336", "hash": "a3462b8840ffa64e78807f593234ce1f", "title": "Initializing Transformer Module with Attention"}, "132": {"path": "/lvdm/modules/attention.py:338-361", "hash": "e6c9501d683f01c7e80d19f350f6e809", "title": "Configuring Transformer Model Attention Layer"}, "133": {"path": "/lvdm/modules/attention.py:362-390", "hash": "2d2fa2fa0f7b8ac68d7ca16c8d67b022", "title": "Neural Attention Module Class"}, "134": {"path": "/lvdm/modules/attention.py:391-409", "hash": "1ecdef29109a261266014869299fe2d2", "title": "Transformer Attention with Memory Optimization"}, "135": {"path": "/lvdm/modules/attention.py:410-448", "hash": "273d1f10a8ade105cb59c2f55ef3a335", "title": "Attention Modules for Computer Vision"}, "136": {"path": "/lvdm/modules/attention.py:449-473", "hash": "b634587f77239dd75c954c827a32368b", "title": "Spatial Self-Attention Class"}, "137": {"path": "/lvdm/modules/attention.py:474-501", "hash": "fbe6bb505e3b662e31b204e68681e345", "title": "Attention Module with Conv2d Layers"}, "138": {"path": "/lvdm/modules/attention.py:502-514", "hash": "c28e1d946b6dd9058bb9a21c96a9d123", "title": "Multi-Head Attention in Transformer"}, "139": {"path": "/lvdm/modules/encoders/condition.py", "hash": "640bce494a114677e5471f1f166d8a1a", "title": "Convolutional CLIP Encoder"}, "140": {"path": "/lvdm/modules/encoders/condition.py:1-37", "hash": "ebdee710f4e5a011747955dfaa886734", "title": "Class Embedder and Abstract Encoder"}, "141": {"path": "/lvdm/modules/encoders/condition.py:38-64", "hash": "f36b87d7134d076c0ebb082c97c59959", "title": "T5 Transformer Text Encoder with Unconditional Conditioning"}, "142": {"path": "/lvdm/modules/encoders/condition.py:65-97", "hash": "6c0350439e2a8da7b5f53f8638cc4f9f", "title": "Condition Encoder Classes"}, "143": {"path": "/lvdm/modules/encoders/condition.py:98-122", "hash": "6823bfdcc55b03fcc760977dcc8747da", "title": "CLIP Model Text Encoder Initialization"}, "144": {"path": "/lvdm/modules/encoders/condition.py:123-152", "hash": "3ddcb380d67f1e16acb53fcfd9ba3f47", "title": "ConditionEncoder and ClipImageEmbedder Classes"}, "145": {"path": "/lvdm/modules/encoders/condition.py:153-184", "hash": "66fe58a377e3dfd7cdd2f67d31ebb5ea", "title": "Frozen OpenCLIP Encoder with Conditioning"}, "146": {"path": "/lvdm/modules/encoders/condition.py:185-215", "hash": "b0a5930970ccade916589e53d0313c6c", "title": "Transformer Encoder Initialization"}, "147": {"path": "/lvdm/modules/encoders/condition.py:216-243", "hash": "f9064855f984775b6809cc7a5a9bfa55", "title": "OpenCLIP Image Encoder Class"}, "148": {"path": "/lvdm/modules/encoders/condition.py:244-268", "hash": "1f47b4d2284dc27714e0ee19c44cb6e7", "title": "Open Clip Model Initialization"}, "149": {"path": "/lvdm/modules/encoders/condition.py:269-300", "hash": "6660ed733d16e8c62ba6a21e4c45dfbd", "title": "Frozen OpenCLIP Image Embedder V2"}, "150": {"path": "/lvdm/modules/encoders/condition.py:301-326", "hash": "b4d746dbf16a19b7a1d27a00d0df602d", "title": "Initializing Image Preprocessing Model"}, "151": {"path": "/lvdm/modules/encoders/condition.py:327-350", "hash": "54fec34a49bdf8a19921273f1520c762", "title": "Image Encoder with Vision Transformer"}, "152": {"path": "/lvdm/modules/encoders/condition.py:351-370", "hash": "ea0c6f3a614f214863440691df79a526", "title": "Conditioned Transformer Encoder: Convolution, Normalization, Patch Dropout"}, "153": {"path": "/lvdm/modules/encoders/condition.py:372-389", "hash": "217af233ed124ade76ecbe0e125f9d34", "title": "FrozenCLIPT5 Encoder Class"}, "154": {"path": "/lvdm/modules/encoders/resampler.py", "hash": "13f0e65461cf199178743c0351db5f9b", "title": "Resampler Module for LvDM"}, "155": {"path": "/lvdm/modules/encoders/resampler.py:1-21", "hash": "803428247557065a9800e979d12e145a", "title": "ImageProjModel for Cross-Attention Projection"}, "156": {"path": "/lvdm/modules/encoders/resampler.py:22-56", "hash": "de34e4b7328e0e3089cd8a577edad040", "title": "PerceiverAttention Implementation"}, "157": {"path": "/lvdm/modules/encoders/resampler.py:57-88", "hash": "2c671a7e4582261927d473cef0a7984f", "title": "Resampler Class with Normalization and Linear Transforms"}, "158": {"path": "/lvdm/modules/encoders/resampler.py:89-125", "hash": "c1ac633415e2c39342b16dbbe4bd1a43", "title": "Resampler Neural Network Module"}, "159": {"path": "/lvdm/modules/encoders/resampler.py:126-145", "hash": "13182402bc2a3a0c0bb5d906941a46b7", "title": "Resampler Module for DynamiCrafter/lvdm"}, "160": {"path": "/lvdm/modules/networks/ae_modules.py", "hash": "fe601fa9d817e53226b8596ad1112c6a", "title": "Attention-Enhanced PyTorch Autoencoder"}, "161": {"path": "/lvdm/modules/networks/ae_modules.py:1-36", "hash": "a8133ca418b6f07728a42f2cfbadb1ec", "title": "Attention Block Modules: Normalization, Conv, Swish"}, "162": {"path": "/lvdm/modules/networks/ae_modules.py:37-64", "hash": "5081bca57c7ceb7994d57df49f2a0481", "title": "Attention Projection Conv2d Layer"}, "163": {"path": "/lvdm/modules/networks/ae_modules.py:66-94", "hash": "70518e67631f0699b6596d6034ad1fb7", "title": "Attention Block Function"}, "164": {"path": "/lvdm/modules/networks/ae_modules.py:95-120", "hash": "36403b372956196c22466b67ef8ede65", "title": "AE_Module: Conv2d with Upsampling"}, "165": {"path": "/lvdm/modules/networks/ae_modules.py:121-147", "hash": "08e0d39b4a59ebad2f921decdbc2fe8c", "title": "Timestep Embedding Convolutional Module"}, "166": {"path": "/lvdm/modules/networks/ae_modules.py:151-172", "hash": "c4644910889283c5d804a431d54035bf", "title": "ResnetBlock: PyTorch Block for Neural Networks"}, "167": {"path": "/lvdm/modules/networks/ae_modules.py:173-194", "hash": "c42ce9b71f480d1a19dd397bca28405c", "title": "Conv2d Layer and Shortcut Connection Initialization"}, "168": {"path": "/lvdm/modules/networks/ae_modules.py:196-225", "hash": "c37f14dcbf92350b3cf98a7c6446d382", "title": "Attention-Based Module Class"}, "169": {"path": "/lvdm/modules/networks/ae_modules.py:226-252", "hash": "907b8ab8bf03ef28f2759697757e08e5", "title": "Timestep Embedding Autoencoder Module"}, "170": {"path": "/lvdm/modules/networks/ae_modules.py:253-274", "hash": "7c9729b000f78c567e802e9a90049028", "title": "Downsampling Network with Resnet Blocks"}, "171": {"path": "/lvdm/modules/networks/ae_modules.py:275-295", "hash": "234504842446c20a3f036136d565f4e1", "title": "Configurable ResNet with Attention for AE"}, "172": {"path": "/lvdm/modules/networks/ae_modules.py:296-321", "hash": "b1cc7096036e96aeef81dccdd27a18f6", "title": "Upsampling Neural Network Module"}, "173": {"path": "/lvdm/modules/networks/ae_modules.py:322-349", "hash": "5eec008e820de50f59e41497f857f2fa", "title": "Neural Network Downsampling and Upsampling"}, "174": {"path": "/lvdm/modules/networks/ae_modules.py:350-380", "hash": "a09f98efa78694d03d1d215dae2b517b", "title": "Encoder Class Definition"}, "175": {"path": "/lvdm/modules/networks/ae_modules.py:381-403", "hash": "8a530d6a45e6c8b2fac1f4bd9bb354c8", "title": "Downsampling AE Module Initialization"}, "176": {"path": "/lvdm/modules/networks/ae_modules.py:404-425", "hash": "373f4f7706893ef5674ce17001f5a273", "title": "Network Module with Downsampling and Attention"}, "177": {"path": "/lvdm/modules/networks/ae_modules.py:426-450", "hash": "e26ddbd08bc1c74fb8fc527fe83df802", "title": "Convolutional Network Encoder"}, "178": {"path": "/lvdm/modules/networks/ae_modules.py:451-479", "hash": "17de702794fdfd1aab47483d81cefd9c", "title": "Encoder-Decoder Architecture"}, "179": {"path": "/lvdm/modules/networks/ae_modules.py:480-503", "hash": "f276a24e5500a752d48c19591f6f37d9", "title": "Autoencoder Model Initialization"}, "180": {"path": "/lvdm/modules/networks/ae_modules.py:504-525", "hash": "8c5203e78526d7a7a45c9bdd5aef8729", "title": "Resnet Block Upsampling with Attention"}, "181": {"path": "/lvdm/modules/networks/ae_modules.py:526-558", "hash": "a72bb1096c2fe351b450da2b90455a80", "title": "Upsampling Convolutional Network Module"}, "182": {"path": "/lvdm/modules/networks/ae_modules.py:559-586", "hash": "dbc1324f6c6e556da36eadb66ec71edf", "title": "AE Decoder Class"}, "183": {"path": "/lvdm/modules/networks/ae_modules.py:587-602", "hash": "12862c8e1329f5d84db30259a107e62b", "title": "Upsampling Resnet Block Model"}, "184": {"path": "/lvdm/modules/networks/ae_modules.py:604-633", "hash": "3dadc908ac6706661aa8129517b2d1d5", "title": "Upsample Decoder Module Initialization"}, "185": {"path": "/lvdm/modules/networks/ae_modules.py:634-657", "hash": "bf369dac81cc1a2e6e09875dd7692fb3", "title": "Residual Network Initialization"}, "186": {"path": "/lvdm/modules/networks/ae_modules.py:658-680", "hash": "c118afa84fdbf9a58d7818b67c9f33a0", "title": "Latent Rescaler Class with Residual and Attention Blocks"}, "187": {"path": "/lvdm/modules/networks/ae_modules.py:681-705", "hash": "977c31e6304a01663ad56f4ef1163b04", "title": "MergedRescaleEncoder Neural Module"}, "188": {"path": "/lvdm/modules/networks/ae_modules.py:706-724", "hash": "5c6527c8619b0c10d130036fc43314cb", "title": "AE Rescaler Decoder and Merged Rescale Decoder Classes"}, "189": {"path": "/lvdm/modules/networks/ae_modules.py:725-744", "hash": "235d0f2fc1c9cd560934f9683bf218e9", "title": "AE Module with Upsampler Class"}, "190": {"path": "/lvdm/modules/networks/ae_modules.py:745-766", "hash": "1b79050b06af9d742731ae4adc318326", "title": "Rescaler and Decoder for Image Processing"}, "191": {"path": "/lvdm/modules/networks/ae_modules.py:767-792", "hash": "24325f23ed2a3827e64f068e8f35ba6b", "title": "Interpolation Conv2d Layer and PostProcessor"}, "192": {"path": "/lvdm/modules/networks/ae_modules.py:793-820", "hash": "da0234cf8624d3d04b717da6f3923a06", "title": "Pre-Trained ResNet Block Autoencoder"}, "193": {"path": "/lvdm/modules/networks/ae_modules.py:821-844", "hash": "31472d573b8cb10ffe8d5347a45a6137", "title": "Gradient-Free Pretrained Network Module"}, "194": {"path": "/lvdm/modules/networks/openaimodel3d.py", "hash": "4991c7c849bdf6a7c8d36e946af62f18", "title": "3D Object Reconstruction Network Model"}, "195": {"path": "/lvdm/modules/networks/openaimodel3d.py:1-39", "hash": "eed4cd3d56baaf02ab2fd7a3c4cda01b", "title": "TimestepEmbedSequential Class"}, "196": {"path": "/lvdm/modules/networks/openaimodel3d.py:40-66", "hash": "a923806d85f4d8bd9266ab7728f6ce82", "title": "Downsampling Layer with Optional Convolutions"}, "197": {"path": "/lvdm/modules/networks/openaimodel3d.py:67-95", "hash": "ada621c289b6249ec7e8515d645e5bea", "title": "Upsample Layer Class"}, "198": {"path": "/lvdm/modules/networks/openaimodel3d.py:96-120", "hash": "71448b01c43d9220f088fd95073cab65", "title": "ResBlock: Adaptable Channel Residual Block"}, "199": {"path": "/lvdm/modules/networks/openaimodel3d.py:121-154", "hash": "6704006b9a8e64cba41f6654d0450ffa", "title": "OpenAI Model 3D Network Class"}, "200": {"path": "/lvdm/modules/networks/openaimodel3d.py:155-185", "hash": "0403a3fc3934d8393abc9b6276f04899", "title": "OpenAI Model 3D Layer Initializer"}, "201": {"path": "/lvdm/modules/networks/openaimodel3d.py:186-210", "hash": "1d2c587ba7dfec0b1f0567a1a2e20093", "title": "Skip-Connected Temporal Conv Neural Block"}, "202": {"path": "/lvdm/modules/networks/openaimodel3d.py:211-239", "hash": "648234dc1321921919ada7d0a05f0d80", "title": "OpenAI Model 3D: Forward Pass and Skip Connection"}, "203": {"path": "/lvdm/modules/networks/openaimodel3d.py:240-259", "hash": "a5cd9a9a2add8ae4b3380c3722093bdd", "title": "TemporalConvBlock: Spatiotemporal Convolutions"}, "204": {"path": "/lvdm/modules/networks/openaimodel3d.py:260-285", "hash": "fed93d9d65a464320eb0ce4122f1571a", "title": "UNet Attention Timestep 3D Model"}, "205": {"path": "/lvdm/modules/networks/openaimodel3d.py:286-302", "hash": "ba70b258c4fbec6ced64133e19b5f646", "title": "UNet Model Parameters"}, "206": {"path": "/lvdm/modules/networks/openaimodel3d.py:303-327", "hash": "6760f9f22f7efd7c7debe868d748c168", "title": "OpenAI Model 3D Class with Configurable Parameters"}, "207": {"path": "/lvdm/modules/networks/openaimodel3d.py:328-351", "hash": "3bb01a6741b6aa6e41fa1d10e38903e8", "title": "UNet Model Initialization"}, "208": {"path": "/lvdm/modules/networks/openaimodel3d.py:352-375", "hash": "acbf6fa66f5887b1b94bbec6ccdea809", "title": "Initializing OpenAI 3D Model Network Attributes"}, "209": {"path": "/lvdm/modules/networks/openaimodel3d.py:376-399", "hash": "f0566be1adf54a45100ffee965c96c0f", "title": "OpenAI 3D Model Neural Network Module"}, "210": {"path": "/lvdm/modules/networks/openaimodel3d.py:400-422", "hash": "8110057ba93a7b52d81c0ac7c40ac9bf", "title": "OpenAI 3D Reconstruction Network"}, "211": {"path": "/lvdm/modules/networks/openaimodel3d.py:423-435", "hash": "f3be67bc764b90dc0da2990a73200987", "title": "3D OpenAI DAVIS Network Model Initialization"}, "212": {"path": "/lvdm/modules/networks/openaimodel3d.py:436-460", "hash": "73631b6f50d33c25d1c298503bcafc32", "title": "OpenAI Model 3D Network Architecture"}, "213": {"path": "/lvdm/modules/networks/openaimodel3d.py:461-478", "hash": "9f761ef03b4f5f8db9ce30df81e5f927", "title": "OpenAI Model 3D Network Layers"}, "214": {"path": "/lvdm/modules/networks/openaimodel3d.py:479-502", "hash": "d4f47bcb14340e92d7021ce923f827d7", "title": "Multi-Attention ResBlock Network Architecture"}, "215": {"path": "/lvdm/modules/networks/openaimodel3d.py:503-521", "hash": "45aba93901acde676fb41d2cc5a7b539", "title": "Spatiotemporal Attention Network Model"}, "216": {"path": "/lvdm/modules/networks/openaimodel3d.py:522-538", "hash": "71baf0bd1c2c60bffde93bbf2bfe99b2", "title": "Configurable Temporal Transformer with Upsampling"}, "217": {"path": "/lvdm/modules/networks/openaimodel3d.py:539-560", "hash": "e9436992594135657bdb7d7e105a8a2e", "title": "OpenAI 3D Model Network Module"}, "218": {"path": "/lvdm/modules/networks/openaimodel3d.py:561-585", "hash": "6e1ffb2e98f85534aa9769886c55fed0", "title": "OpenAI Model Data Processing"}, "219": {"path": "/lvdm/modules/networks/openaimodel3d.py:586-603", "hash": "d50ab5ba43c8d13d62168b5f6a6023f8", "title": "Adapter Feature Integration"}, "220": {"path": "/lvdm/modules/x_transformer.py", "hash": "ee84234b9a9cf7efd69326167a327ca7", "title": "X-Transformer Implementation: Neural Modules and Embeddings"}, "221": {"path": "/lvdm/modules/x_transformer.py:1-41", "hash": "515a24f88b7f8d264dbb16478f576483", "title": "X-Transformers: Time Series Model Implementation"}, "222": {"path": "/lvdm/modules/x_transformer.py:42-93", "hash": "d2762091adc343cd00ba42a821ab09d7", "title": "Sinusoidal Transformation Module\nwith Buffer and Conditional Functions"}, "223": {"path": "/lvdm/modules/x_transformer.py:94-133", "hash": "9b6137eb8af267e72ba6c0a84078ca73", "title": "Scaling and Rezero Classes Definition"}, "224": {"path": "/lvdm/modules/x_transformer.py:134-173", "hash": "b6ff8c320c7e4783f35faec8fb4cd9f9", "title": "Neural Network Modules for Normalization"}, "225": {"path": "/lvdm/modules/x_transformer.py:174-216", "hash": "12d0f2505dd5152dc0538a5fa053c34b", "title": "Implementing Transformer Components in x_transformer.py"}, "226": {"path": "/lvdm/modules/x_transformer.py:217-248", "hash": "b8e4759821f70905f9d4a476da679c4f", "title": "Multi-Head Attention Module Implementation"}, "227": {"path": "/lvdm/modules/x_transformer.py:250-281", "hash": "6f3a5cee43165e6f5410cd9f43aa07f1", "title": "Explicit Top-k Sparse Attention Module"}, "228": {"path": "/lvdm/modules/x_transformer.py:282-305", "hash": "fe24f751f30d486b9c4126320192b71d", "title": "Transformer Initialization"}, "229": {"path": "/lvdm/modules/x_transformer.py:306-335", "hash": "1d945aa8cda59069f55a6664cc0543db", "title": "Multi-Head Attention in Transformer"}, "230": {"path": "/lvdm/modules/x_transformer.py:336-363", "hash": "d36fc86219e1324db9170575343596e4", "title": "Transformer Attention Processing"}, "231": {"path": "/lvdm/modules/x_transformer.py:364-401", "hash": "3543ee9e159c93a1c17bb51267e082c9", "title": "Attention Layer Class: Deep Learning Models"}, "232": {"path": "/lvdm/modules/x_transformer.py:402-428", "hash": "a7abc19a5fb883371a43bd8df2a040ac", "title": "Xformer Module Initialization"}, "233": {"path": "/lvdm/modules/x_transformer.py:430-447", "hash": "4028a9feb38931b96913276dcfdd56bc", "title": "Layer Types Variable Setting"}, "234": {"path": "/lvdm/modules/x_transformer.py:448-472", "hash": "f948c5aad0559471c96c855cac1ac4ff", "title": "Dynamic Layer Creation in XTransformer"}, "235": {"path": "/lvdm/modules/x_transformer.py:474-510", "hash": "45425b79675c0f9d562af4318ea46a4f", "title": "Transformer Module with Normalization and Residuals"}, "236": {"path": "/lvdm/modules/x_transformer.py:511-543", "hash": "544dc261b0a6c4b991cdb3296cec5611", "title": "Layer-dependent Attention Operation"}, "237": {"path": "/lvdm/modules/x_transformer.py:547-576", "hash": "9d6a246c8e03671627cc3fcb42036a77", "title": "TransformerWrapper Class"}, "238": {"path": "/lvdm/modules/x_transformer.py:577-607", "hash": "aaca63f27b19ef3db250404674fed00d", "title": "Memory-Enhanced Transformer Module"}, "239": {"path": "/lvdm/modules/x_transformer.py:608-636", "hash": "408542dd632fb294ccf7236510cf1f1f", "title": "X Transformer: Embedding, Attention, and More"}, "240": {"path": "/lvdm/modules/x_transformer.py:637-639", "hash": "ae4fe036962ea1a1a80b573b8a7b654d", "title": "Output and Attention Maps from X-Transformer"}, "241": {"path": "/prompts/test_prompts.txt", "hash": "e146c85ea00aac9e01086b43806f242b", "title": "Inspiration Prompts"}, "242": {"path": "/requirements.txt", "hash": "70ea0f5d7aa62afbf1b69e9633cf09d7", "title": "Python Library Dependencies in Requirements.txt"}, "243": {"path": "/scripts/evaluation/ddp_wrapper.py", "hash": "abff445ea923dbbcc98cc27c3713b9a0", "title": "Distributed DDP Wrapper Setup"}, "244": {"path": "/scripts/evaluation/ddp_wrapper.py:1-35", "hash": "1cfd52a9ab5690ec29e459f3a12790fb", "title": "Distributed DDP Wrapper"}, "245": {"path": "/scripts/evaluation/ddp_wrapper.py:37-47", "hash": "90478f201d13295647f2696dd92dbef0", "title": "Distributed Data Parallel Inference Setup"}, "246": {"path": "/scripts/evaluation/funcs.py", "hash": "9908c917e7857c3e619935abd86d1d04", "title": "DDPM Sampling Functions"}, "247": {"path": "/scripts/evaluation/funcs.py:1-29", "hash": "09c25c2188c950416b2ed3a578219cb3", "title": "Batch DDIM Sampling Function"}, "248": {"path": "/scripts/evaluation/funcs.py:31-57", "hash": "1fb9864cb188aa75e9ee5bc87b6913db", "title": "Embedding Images with Conditioning"}, "249": {"path": "/scripts/evaluation/funcs.py:58-80", "hash": "fb7baf54415951a1a4be7fd274755f5d", "title": "DDim Image Generation Function"}, "250": {"path": "/scripts/evaluation/funcs.py:81-112", "hash": "966e492cbdd9e432066b22516e45c892", "title": "Load Checkpoint and Prompts Functions"}, "251": {"path": "/scripts/evaluation/funcs.py:113-139", "hash": "ee1e40664d15ea4de83f4148b8c5a627", "title": "Video Frames Processing Function"}, "252": {"path": "/scripts/evaluation/funcs.py:140-163", "hash": "c4889f1c2f318e47577d0eddbbae89c6", "title": "Batch and Resize Frames from Video and Images"}, "253": {"path": "/scripts/evaluation/funcs.py:164-181", "hash": "4a9915f4634091d88ec7206597f05542", "title": "Multimedia Reader Function"}, "254": {"path": "/scripts/evaluation/funcs.py:182-204", "hash": "6ca85194647ae115ea7e5fdae218c70f", "title": "Video Encoding, Saving, and Rearrangement Functions"}, "255": {"path": "/scripts/evaluation/funcs.py:205-205", "hash": "2c2e649042e94a5769dd6378a8447999", "title": "Return Value of 'z'"}, "256": {"path": "/scripts/evaluation/inference.py", "hash": "04f726224bc5dd5d78d4f51d2ecd21de", "title": "Deep Learning Video Synthesis Inference"}, "257": {"path": "/scripts/evaluation/inference.py:1-31", "hash": "300a42a42d5cb6acc0b0a667430c5543", "title": "Model Loading and DDIMSampler Functions"}, "258": {"path": "/scripts/evaluation/inference.py:32-62", "hash": "dace6a32c2cefa66e8ccca911106a00b", "title": "Model Loading and Data Preparation"}, "259": {"path": "/scripts/evaluation/inference.py:63-86", "hash": "95b8002e04b6fddb59ebb1205e10c768", "title": "Load, Convert, and Return Tensors from Prompt Files"}, "260": {"path": "/scripts/evaluation/inference.py:87-112", "hash": "6ca758cb8fe4c2a9cb3b951fb8f252a9", "title": "Video Processing Script"}, "261": {"path": "/scripts/evaluation/inference.py:113-138", "hash": "4f2090cb8f48b5f1f34f66dfb3f7d865", "title": "Deep Learning Video Framing"}, "262": {"path": "/scripts/evaluation/inference.py:139-162", "hash": "97c6247731bcdcd7cea6379bfbf70f24", "title": "DDIM Sampler for Image Synthesis"}, "263": {"path": "/scripts/evaluation/inference.py:163-185", "hash": "2dee334c02fe63ac54e4ebc50fd16521", "title": "Hybrid Conditioning for Model Inputs"}, "264": {"path": "/scripts/evaluation/inference.py:186-211", "hash": "00cc326769576e5c58337253ef267b2c", "title": "Conditional Diffusion Model: Inference and Sampling"}, "265": {"path": "/scripts/evaluation/inference.py:212-235", "hash": "c5dd267214a5a5416340cd0900102b59", "title": "Model Instantiation and GPU Assignment"}, "266": {"path": "/scripts/evaluation/inference.py:237-259", "hash": "6e63490065b330eb00e00c9493d5deb4", "title": "Checkpoint Evaluation Process"}, "267": {"path": "/scripts/evaluation/inference.py:260-278", "hash": "1df9526cbe597ff894dc19bbaed06069", "title": "Distributed AMP Inference and Evaluation"}, "268": {"path": "/scripts/evaluation/inference.py:280-297", "hash": "cb6a488a16bb1db6fc236cf53144abef", "title": "Image Synthesis with Prompts"}, "269": {"path": "/scripts/evaluation/inference.py:298-306", "hash": "546f8c1216e76306fbba6cdf1542d448", "title": "Command-Line Arguments for Inference Script"}, "270": {"path": "/scripts/evaluation/inference.py:307-317", "hash": "f30c84a8e59491a4b43e07f7f0b3af05", "title": "Command Line Arguments for AI Image Generation"}, "271": {"path": "/scripts/evaluation/inference.py:318-329", "hash": "7118ae63116aa3c2df13d4fb09d652c8", "title": "Command-line GPU Inference Seeder"}, "272": {"path": "/scripts/gradio/i2v_test.py", "hash": "a44cc3d1fba7783f8e9b0f91f15f921b", "title": "Image2Video Synthesis Script"}, "273": {"path": "/scripts/gradio/i2v_test.py:1-26", "hash": "0688f7bcec90f113f9e723110a82fd78", "title": "Image2Video Model Implementation"}, "274": {"path": "/scripts/gradio/i2v_test.py:27-53", "hash": "526ed69504e3f2d8f3bd8431bcb28c24", "title": "Image Preprocessing for Inversion Model"}, "275": {"path": "/scripts/gradio/i2v_test.py:55-79", "hash": "e81ed926da4728d219a66cf2b7de0973", "title": "DDIM Sampling Script"}, "276": {"path": "/scripts/gradio/i2v_test.py:80-99", "hash": "6cfc812a93af1ab94d5d8490e97d08d3", "title": "Script Snippet for Model Download and Video Processing"}, "277": {"path": "/scripts/gradio/i2v_test.py:101-104", "hash": "b9970030407f12e35f960ede00124b9d", "title": "Image to Video Script"}, "278": {"path": "/scripts/run.sh", "hash": "0f64badec274857b5286f817a2cb2ee7", "title": "Dynamic Rafter's Inference Script"}, "279": {"path": "/scripts/run_mp.sh", "hash": "3ff7161b4b84186271a66f32d52aee81", "title": "Multi-GPU DynamiCrafter Inference"}, "280": {"path": "/scripts/run_mp.sh:1-38", "hash": "75ff0233dd25729450806e72bfbb16b3", "title": "Multi-GPU Inference on DynamiCrafter Model"}, "281": {"path": "/scripts/run_mp.sh:39-42", "hash": "c445198b3939785f4ff308a5e47c0981", "title": "Command-Line Options for DynamiCrafter"}, "282": {"path": "/utils/utils.py", "hash": "e4089953adc0ae1ade4b7e035bc77dd5", "title": "Parameter Counting and Matching Functions"}, "283": {"path": "/utils/utils.py:1-40", "hash": "f2e3da952d0bbd7cc5c97c5cae307779", "title": "Parameter Counting and Instantiation Functions"}, "284": {"path": "/utils/utils.py:41-74", "hash": "3bedaef01b54e1ad394a5949372f4e76", "title": "Utility Functions for Loading, Resizing, and Initializing"}, "285": {"path": "/utils/utils.py:75-77", "hash": "10f81036258ccaefad582ed818b14ee7", "title": "NCCL-Powered Distributed Training Init Method"}}}